{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# Adagrad --- \u4f7f\u7528Gluon\n\n\n\u5728`Gluon`\u91cc\uff0c\u4f7f\u7528Adagrad\u5f88\u5bb9\u6613\u3002\u6211\u4eec\u65e0\u9700\u91cd\u65b0\u5b9e\u73b0\u5b83\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "1"
                }
            }, 
            "outputs": [], 
            "source": "import mxnet as mx\nfrom mxnet import autograd\nfrom mxnet import gluon\nfrom mxnet import ndarray as nd\nimport numpy as np\nimport random\n\nmx.random.seed(1)\nrandom.seed(1)\n\n# \u751f\u6210\u6570\u636e\u96c6\u3002\nnum_inputs = 2\nnum_examples = 1000\ntrue_w = [2, -3.4]\ntrue_b = 4.2\nX = nd.random_normal(scale=1, shape=(num_examples, num_inputs))\ny = true_w[0] * X[:, 0] + true_w[1] * X[:, 1] + true_b\ny += .01 * nd.random_normal(scale=1, shape=y.shape)\ndataset = gluon.data.ArrayDataset(X, y)\n\nnet = gluon.nn.Sequential()\nnet.add(gluon.nn.Dense(1))\nsquare_loss = gluon.loss.L2Loss()"
        }, 
        {
            "source": "\u6211\u4eec\u9700\u8981\u5728`gluon.Trainer`\u4e2d\u6307\u5b9a\u4f18\u5316\u7b97\u6cd5\u540d\u79f0`adagrad`\u5e76\u8bbe\u7f6e\u53c2\u6570\u3002\u4f8b\u5982\u8bbe\u7f6e\u521d\u59cb\u5b66\u4e60\u7387`learning_rate`\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "2"
                }
            }, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib as mpl\nmpl.rcParams['figure.dpi']= 120\nimport matplotlib.pyplot as plt\n\ndef train(batch_size, lr, epochs, period):\n    assert period >= batch_size and period % batch_size == 0\n    net.collect_params().initialize(mx.init.Normal(sigma=1), force_reinit=True)\n    # Adagrad\u3002\n    trainer = gluon.Trainer(net.collect_params(), 'adagrad',\n                            {'learning_rate': lr})\n    data_iter = gluon.data.DataLoader(dataset, batch_size, shuffle=True)\n    total_loss = [np.mean(square_loss(net(X), y).asnumpy())]\n    \n    for epoch in range(1, epochs + 1):\n        for batch_i, (data, label) in enumerate(data_iter):\n            with autograd.record():\n                output = net(data)\n                loss = square_loss(output, label)\n            loss.backward()\n            trainer.step(batch_size)\n            if batch_i * batch_size % period == 0:\n                total_loss.append(np.mean(square_loss(net(X), y).asnumpy()))\n        print(\"Batch size %d, Learning rate %f, Epoch %d, loss %.4e\" % \n              (batch_size, trainer.learning_rate, epoch, total_loss[-1]))\n\n    print('w:', np.reshape(net[0].weight.data().asnumpy(), (1, -1)), \n          'b:', net[0].bias.data().asnumpy()[0], '\\n')\n    x_axis = np.linspace(0, epochs, len(total_loss), endpoint=True)\n    plt.semilogy(x_axis, total_loss)\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.show()"
        }, 
        {
            "source": "\u4f7f\u7528Adagrad\uff0c\u6700\u7ec8\u5b66\u5230\u7684\u53c2\u6570\u503c\u4e0e\u771f\u5b9e\u503c\u8f83\u63a5\u8fd1\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "3"
                }
            }, 
            "outputs": [], 
            "source": "train(batch_size=10, lr=0.9, epochs=3, period=10)"
        }, 
        {
            "source": "## \u7ed3\u8bba\n\n* \u4f7f\u7528`Gluon`\u7684`Trainer`\u53ef\u4ee5\u8f7b\u677e\u4f7f\u7528Adagrad\u3002\n\n## \u7ec3\u4e60\n\n* \u5c1d\u8bd5\u4f7f\u7528\u5176\u4ed6\u7684\u521d\u59cb\u5b66\u4e60\u7387\uff0c\u7ed3\u679c\u6709\u4ec0\u4e48\u53d8\u5316\uff1f\n\n**\u5410\u69fd\u548c\u8ba8\u8bba\u6b22\u8fce\u70b9**[\u8fd9\u91cc](https://discuss.gluon.ai/t/topic/2274)", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 1.6 (Unsupported)", 
            "name": "python2", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}