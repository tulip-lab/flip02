{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Modern Data Science \n**(Module 03: Pattern Classification)**\n\n---\n- Materials in this module include resources collected from various open-source online repositories.\n- You are free to use, change and distribute this package.\n\nPrepared by and for \n**Student Members** |\n2006-2018 [TULIP Lab](http://www.tulip.org.au), Australia\n\n---\n\n\n# Session D - Hidden Markov Model: HMM\n\nIn this sesion, we will study Hidden Markov Model.The Hidden Markov Model based on the Markov Model and solve the limitations of Markov Model. We will show the formalism and example of HMM.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# import related package\nfrom IPython.core.display import HTML\nimport requests\nimport numpy as np\nimport pandas as pd\np=print"
        }, 
        {
            "source": "## Is Your Girlfriend Cheating on You?", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Your girlfriend Mary has been exhibiting odd sequences of behavior. You suspect cheating. You don't want to falsely accuse her but something is off. Is there a way to reason about the situation so you can decide if you should confront her using the limited information you have?\n\nYou recall Hidden Markov Models are a tool for these situations. Mary's activities represent a sequence of **`hidden states`**, while her observed behavior represents a sequence of **`emissions`**. Because you don't talk much and you believe she may lie to you, all you can do is try to guess her true state via observations taken over time. \n\nFirst you define the range of possible states **`M`**. You know Mary has a strong work ethic, both professionally and actively. So you conclude that when not with you, she could be at __`Work, Gym,`__ or __`Cheating`__. \n\nThese states are hidden to you and cannot be observed directly.\n\nYou do not know the initial probabilities **`pi`**, of which state she could be in. You decide that Work or the Gym is equiprobable, and that there is a small percent she is cheating.\n\n>**pi = [0.4, 0.4, 0.2]**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# define states\n# work --> gym --> cheating\n\n# initial probability of being in state k, for M states\nstates = ['work', 'gym', 'cheating']\npi = np.array([0.4, 0.4, 0.2])\n\n# pi \n(pd.Series(pi, index=states, name='states'))"
        }, 
        {
            "source": "Next you must guess about the transition probabilities for the matrix of possible states. For example, if Mary was working, what is the probability she would continue working, then transition to the gym, then transition to cheating? \n\nThese are difficult questions to ask, no doubt, but you push forward.\n\nYou start with the state transitions for work. You reason that the probability is high, that Mary would keep working given she is already working. It is also highly probable she could transition from work to the gym. You assign a low probability that she could transition from work to cheating.\n\n>**work = [0.6, 0.3, 0.1]**\n\nThe gym is less certain. You reason she could transition from the gym state to any other state with equal probability.\n\n>**gym = [0.33, 0.33, 0.33]**\n\nFinally, you consider if she were cheating, that you have no idea what state she would transition to afterwards. \n\n>**cheating = [0.33, 0.33, 0.33]**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# a or alpha = transition probability matrix of changing states given a state\n# matrix is size (M x M) where M is number of states\n\na_df = pd.DataFrame(columns=states, index=states)\na_df.loc[states[0]] = [.6, .3, .1]\na_df.loc[states[1]] = [.33, .33, .33]\na_df.loc[states[2]] = [.33, .33, .33]\np(a_df)\n\na = a_df.values\np('\\n',a, a.shape)"
        }, 
        {
            "source": "The final requirement is to reason about the observation aka _-`emission`__ probabilities. These are the probabilities that you would observe a particular behavior given she is in a particular state.\n\nAgain you do not know Mary's true states because you don't talk, and you believe she may lie to you. Instead you focus on observations you believe are linked to her true state. \n\nThese observations are __`makeup, athletic dress`__, and __`locked cell phone.`__ \n\nGiven Mary is in the work state, it is highly probable that she would wear makeup to work, very low probability that she would dress athletically, and high probability she would lock her phone.\n\n>__work_emission = [0.4, 0.1, 0.5]__\n\nMary is an avid gym goer. Given the gym state, she is unlikely to wear makeup, likely to dress athletically, and is very likely to lock her phone.\n\n>__gym_emission = [0.1, 0.3, 0.6]__\n\nIf she is cheating, you figure you clearly don't know Mary like you thought, and you certainly do not know the probability that she will emit any of these behaviors if she is cheating therefore you set them equiprobable. \n\n>__cheating_emission = [0.33, 0.33, 0.33]__ ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Emission probabilities\n# b or beta = observation probabilities given state\n# matrix is size (M x O) where M is number of states \n# and O is number of different possible observations\n\nemit = ['makeup', 'dress', 'phone']\nb_df = pd.DataFrame(columns=emit, index=states)\nb_df.loc[states[0]] = [0.4, 0.1, 0.5]\nb_df.loc[states[1]] = [0.1, 0.3, 0.6]\nb_df.loc[states[2]] = [0.33, 0.33, 0.33]\np(b_df)\n\nb = b_df.values\np('\\n', b, b.shape)"
        }, 
        {
            "source": "Now we simply record the observation sequence", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# observation sequence of Mary's behaviors\n# observations are encoded numerically\n\nobs_map = {'makeup':0, 'dress':1, 'phone':2}\nobs = np.array([0,2,2,1,1,0,2,1,2,1,1,2,0,2])\n\ninv_obs_map = dict((v,k) for k, v in obs_map.items())\nobs_seq = [inv_obs_map[v] for v in list(obs)]\n\np( pd.DataFrame(np.column_stack([obs, obs_seq]), \n                columns=['Obs_code', 'Obs_seq']) )"
        }, 
        {
            "source": "### The HMM can answer the question, _given this sequence of observed behaviors and our model parameters, what is the most likely sequence of hidden states?_\n\nYou can calculate this using the __`Viterbi`__ algorithm.\n\nHigh level, the Viterbi algorithm increments over each time step, finding the __`maximum`__ probability of any path that gets to state __`i`__ at time __`t`__, that ___also___ has the correct observations for the sequence up to time __`t`__.\n\nThe algorithm also keeps track of the state with the highest probability at each stage. At the end of the sequence, the algorithm will iterate backwards selecting the state that \"won\" each time step, and thus creating the most likely path, or likely sequence of hidden states that led to the sequence of observations. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# define Viterbi algorithm for shortest path\n\n\ndef viterbi(pi, a, b, obs):\n    \n    nStates = np.shape(b)[0]\n    T = np.shape(obs)[0]\n    \n    # init blank path\n    path = np.zeros(T)\n    # delta --> highest probability of any path that reaches state i\n    delta = np.zeros((nStates, T))\n    # phi --> argmax by time step for each state\n    phi = np.zeros((nStates, T))\n    \n    # init delta and phi \n    delta[:, 0] = pi * b[:, obs[0]]\n    phi[:, 0] = 0\n\n    p('\\nStart Walk Forward\\n')    \n    # the forward algorithm extension\n    for t in range(1, T):\n        for s in range(nStates):\n            delta[s, t] = np.max(delta[:, t-1] * a[:, s]) * b[s, obs[t]] \n            phi[s, t] = np.argmax(delta[:, t-1] * a[:, s])\n            p('s={s} and t={t}: phi[{s}, {t}] = {phi}'.format(s=s, t=t, phi=phi[s, t]))\n    \n    # find optimal path\n    p('-'*50)\n    p('Start Backtrace\\n')\n    path[T-1] = np.argmax(delta[:, T-1])\n    #p('init path\\n    t={} path[{}-1]={}\\n'.format(T-1, T, path[T-1]))\n    for t in range(T-2, -1, -1):\n        path[t] = phi[path[t+1], [t+1]]\n        #p(' '*4 + 't={t}, path[{t}+1]={path}, [{t}+1]={i}'.format(t=t, path=path[t+1], i=[t+1]))\n        p('path[{}] = {}'.format(t, path[t]))\n        \n    return path, delta, phi\n\npath, delta, phi = viterbi(pi, a, b, obs)\np('\\nsingle best state path: \\n', path)\np('delta:\\n', delta)\np('phi:\\n', phi)\np('this delta',delta)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "(pd.DataFrame(delta, index=states).T)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "state_map = {0:'work', 1:'gym', 2:'cheating'}\nstate_path = [state_map[v] for v in path]\n\n(pd.DataFrame()\n .assign(Observation=obs_seq)\n .assign(Best_Path=state_path))"
        }, 
        {
            "source": "### Conclusion\n\nUsing the Hidden Markov Model framework and some reasonable assumptions, we were able to make an educated guess about Mary's true sequence of states without direct observation of those states. Instead we used the directly observable emmissions as a link to map the observable to the hidden. ", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }, 
        "anaconda-cloud": {}
    }, 
    "nbformat": 4
}