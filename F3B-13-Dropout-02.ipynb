{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# \u4e22\u5f03\u6cd5\uff08Dropout\uff09--- \u4f7f\u7528Gluon\n\n\u672c\u7ae0\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528``Gluon``\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u4f7f\u7528\u4e22\u5f03\u6cd5 (Dropout)\u3002\n\n\n## \u5b9a\u4e49\u6a21\u578b\u5e76\u6dfb\u52a0\u4e22\u5f03\u5c42\n\n\u6709\u4e86`Gluon`\uff0c\u6211\u4eec\u6a21\u578b\u7684\u5b9a\u4e49\u5de5\u4f5c\u53d8\u5f97\u7b80\u5355\u4e86\u8bb8\u591a\u3002\u6211\u4eec\u53ea\u9700\u8981\u5728\u5168\u8fde\u63a5\u5c42\u540e\u6dfb\u52a0`gluon.nn.Dropout`\u5c42\u5e76\u6307\u5b9a\u5143\u7d20\u4e22\u5f03\u6982\u7387\u3002\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u63a8\u8350\u628a\n\u66f4\u9760\u8fd1\u8f93\u5165\u5c42\u7684\u5143\u7d20\u4e22\u5f03\u6982\u7387\u8bbe\u7684\u66f4\u5c0f\u4e00\u70b9\u3002\u8fd9\u4e2a\u8bd5\u9a8c\u4e2d\uff0c\u6211\u4eec\u628a\u7b2c\u4e00\u5c42\u5168\u8fde\u63a5\u540e\u7684\u5143\u7d20\u4e22\u5f03\u6982\u7387\u8bbe\u4e3a0.2\uff0c\u628a\u7b2c\u4e8c\u5c42\u5168\u8fde\u63a5\u540e\u7684\u5143\u7d20\u4e22\u5f03\u6982\u7387\u8bbe\u4e3a0.5\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "5"
                }
            }, 
            "outputs": [], 
            "source": "from mxnet.gluon import nn\n\nnet = nn.Sequential()\ndrop_prob1 = 0.2\ndrop_prob2 = 0.5\n\nwith net.name_scope():\n    net.add(nn.Flatten())\n    # \u7b2c\u4e00\u5c42\u5168\u8fde\u63a5\u3002\n    net.add(nn.Dense(256, activation=\"relu\"))\n    # \u5728\u7b2c\u4e00\u5c42\u5168\u8fde\u63a5\u540e\u6dfb\u52a0\u4e22\u5f03\u5c42\u3002\n    net.add(nn.Dropout(drop_prob1))\n    # \u7b2c\u4e8c\u5c42\u5168\u8fde\u63a5\u3002\n    net.add(nn.Dense(256, activation=\"relu\"))\n    # \u5728\u7b2c\u4e8c\u5c42\u5168\u8fde\u63a5\u540e\u6dfb\u52a0\u4e22\u5f03\u5c42\u3002\n    net.add(nn.Dropout(drop_prob2))\n    net.add(nn.Dense(10))\nnet.initialize()"
        }, 
        {
            "source": "## \u8bfb\u53d6\u6570\u636e\u5e76\u8bad\u7ec3\n\n\u8fd9\u8ddf\u4e4b\u524d\u6ca1\u4ec0\u4e48\u4e0d\u540c\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "6"
                }
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/gpfs/fs01/user/s05b-0294eb3de63d2e-b5498f932ea5/.local/lib/python2.7/site-packages/matplotlib/style/core.py:203: UserWarning: In /gpfs/fs01/user/s05b-0294eb3de63d2e-b5498f932ea5/.config/matplotlib/stylelib/my_custom_style.mplstyle: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n  warnings.warn(message)\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 0. Loss: 0.823928, Train acc 0.694227, Test acc 0.815004\nEpoch 1. Loss: 0.511527, Train acc 0.812834, Test acc 0.836038\nEpoch 2. Loss: 0.452048, Train acc 0.835069, Test acc 0.864383\nEpoch 3. Loss: 0.412793, Train acc 0.851462, Test acc 0.858273\nEpoch 4. Loss: 0.394609, Train acc 0.855101, Test acc 0.877204\n"
                }
            ], 
            "source": "import sys\nsys.path.append('..')\nimport utils\nfrom mxnet import nd\nfrom mxnet import autograd\nfrom mxnet import gluon\n\nbatch_size = 256\ntrain_data, test_data = utils.load_data_fashion_mnist(batch_size)\n\nsoftmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\ntrainer = gluon.Trainer(net.collect_params(), \n                        'sgd', {'learning_rate': 0.5})\n\nfor epoch in range(5):\n    train_loss = 0.\n    train_acc = 0.\n    for data, label in train_data:\n        with autograd.record():\n            output = net(data)\n            loss = softmax_cross_entropy(output, label)\n        loss.backward()\n        trainer.step(batch_size)\n\n        train_loss += nd.mean(loss).asscalar()\n        train_acc += utils.accuracy(output, label)\n\n    test_acc = utils.evaluate_accuracy(test_data, net)\n    print(\"Epoch %d. Loss: %f, Train acc %f, Test acc %f\" % (\n        epoch, train_loss/len(train_data), \n        train_acc/len(train_data), test_acc))"
        }, 
        {
            "source": "## \u7ed3\u8bba\n\n\u901a\u8fc7`Gluon`\u6211\u4eec\u53ef\u4ee5\u66f4\u65b9\u4fbf\u5730\u6784\u9020\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u5e76\u4f7f\u7528\u4e22\u5f03\u6cd5\u3002\n\n## \u7ec3\u4e60\n\n- \u5c1d\u8bd5\u4e0d\u540c\u5143\u7d20\u4e22\u5f03\u6982\u7387\u53c2\u6570\u7ec4\u5408\uff0c\u770b\u770b\u7ed3\u679c\u6709\u4ec0\u4e48\u4e0d\u540c\u3002\n\n**\u5410\u69fd\u548c\u8ba8\u8bba\u6b22\u8fce\u70b9**[\u8fd9\u91cc](https://discuss.gluon.ai/t/topic/1279)", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 1.6 (Unsupported)", 
            "name": "python2", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}