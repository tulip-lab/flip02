{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# Modern Data Science \n**(Module 03: Pattern Classification)**\n\n---\n- Materials in this module include resources collected from various open-source online repositories.\n- You are free to use, change and distribute this package.\n\nPrepared by and for \n**Student Members** |\n2006-2018 [TULIP Lab](http://www.tulip.org.au), Australia\n\n---\n\n\n# Session L - Random numbers and probability models\n\nImport related package", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nfrom numba import jit"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Fetching package metadata ...........\nSolving package specifications: .\n\nPackage plan for installation in environment /opt/conda/envs/DSX-Python35:\n\nThe following NEW packages will be INSTALLED:\n\n    _r-mutex:               1.0.0-mro_2               \n    binutils_impl_linux-64: 2.28.1-had2808c_3         \n    binutils_linux-64:      7.2.0-26                  \n    gcc_impl_linux-64:      7.2.0-habb00fd_3          \n    gcc_linux-64:           7.2.0-26                  \n    gfortran_impl_linux-64: 7.2.0-hdf63c60_3          \n    gfortran_linux-64:      7.2.0-26                  \n    gxx_impl_linux-64:      7.2.0-hdf63c60_3          \n    gxx_linux-64:           7.2.0-26                  \n    libcurl:                7.59.0-h1ad7b7a_0         \n    mro-base:               3.4.3-h1c2f66e_0          \n    r-assertthat:           0.2.0-mro343h889e2dd_0    \n    r-bh:                   1.65.0_1-mro343h889e2dd_0 \n    r-bindr:                0.1-mro343h889e2dd_0      \n    r-bindrcpp:             0.2-mro343h599a50d_0      \n    r-bit:                  1.1_12-mro343h086d26f_0   \n    r-bit64:                0.9_7-mro343h086d26f_0    \n    r-blob:                 1.1.0-mro343h889e2dd_0    \n    r-cli:                  1.0.0-mro343h889e2dd_0    \n    r-crayon:               1.3.4-mro343h889e2dd_0    \n    r-dbi:                  0.7-mro343h889e2dd_0      \n    r-dbplyr:               1.1.0-mro343h889e2dd_0    \n    r-digest:               0.6.13-mro343h086d26f_0   \n    r-dplyr:                0.7.4-mro343h599a50d_0    \n    r-glue:                 1.2.0-mro343h086d26f_0    \n    r-magrittr:             1.5-mro343h889e2dd_0      \n    r-memoise:              1.1.0-mro343h889e2dd_0    \n    r-pillar:               1.0.1-mro343h889e2dd_0    \n    r-pkgconfig:            2.0.1-mro343h889e2dd_0    \n    r-plogr:                0.1_1-mro343h889e2dd_0    \n    r-purrr:                0.2.4-mro343h086d26f_0    \n    r-r6:                   2.2.2-mro343_0            \n    r-rcpp:                 0.12.14-mro343h599a50d_0  \n    r-rlang:                0.1.6-mro343h086d26f_0    \n    r-rsqlite:              2.0-mro343h599a50d_0      \n    r-tibble:               1.4.1-mro343h086d26f_0    \n    r-utf8:                 1.1.2-mro343h086d26f_0    \n    rpy2:                   2.9.1-py35mro343h14c3975_0\n\nThe following packages will be UPDATED:\n\n    curl:                   7.55.1-h78862de_4          --> 7.59.0-h84994c4_0      \n    pycurl:                 7.43.0-py35h7a9665c_3      --> 7.43.0.1-py35hb7f436b_0\n\n_r-mutex-1.0.0 100% |################################| Time: 0:00:00   2.69 MB/s\nbinutils_impl_ 100% |################################| Time: 0:00:00  37.48 MB/s\nbinutils_linux 100% |################################| Time: 0:00:00  15.84 MB/s\ngcc_impl_linux 100% |################################| Time: 0:00:02  35.31 MB/s\ngcc_linux-64-7 100% |################################| Time: 0:00:00  15.51 MB/s\ngfortran_impl_ 100% |################################| Time: 0:00:00  38.01 MB/s\ngxx_impl_linux 100% |################################| Time: 0:00:00  32.51 MB/s\ngfortran_linux 100% |################################| Time: 0:00:00  16.12 MB/s\ngxx_linux-64-7 100% |################################| Time: 0:00:00  15.63 MB/s\nlibcurl-7.59.0 100% |################################| Time: 0:00:00  49.87 MB/s\ncurl-7.59.0-h8 100% |################################| Time: 0:00:00  47.12 MB/s\npycurl-7.43.0. 100% |################################| Time: 0:00:00  41.55 MB/s\nmro-base-3.4.3 100% |################################| Time: 0:00:01  31.30 MB/s\nr-assertthat-0 100% |################################| Time: 0:00:00  38.58 MB/s\nr-bh-1.65.0_1- 100% |################################| Time: 0:00:00  29.59 MB/s\nr-bindr-0.1-mr 100% |################################| Time: 0:00:00  22.50 MB/s\nr-bit-1.1_12-m 100% |################################| Time: 0:00:00  48.69 MB/s\nr-crayon-1.3.4 100% |################################| Time: 0:00:00  50.21 MB/s\nr-dbi-0.7-mro3 100% |################################| Time: 0:00:00  49.33 MB/s\nr-digest-0.6.1 100% |################################| Time: 0:00:00  46.27 MB/s\nr-glue-1.2.0-m 100% |################################| Time: 0:00:00  44.71 MB/s\nr-magrittr-1.5 100% |################################| Time: 0:00:00  49.36 MB/s\nr-pkgconfig-2. 100% |################################| Time: 0:00:00  27.07 MB/s\nr-plogr-0.1_1- 100% |################################| Time: 0:00:00  22.44 MB/s\nr-r6-2.2.2-mro 100% |################################| Time: 0:00:00  37.35 MB/s\nr-rcpp-0.12.14 100% |################################| Time: 0:00:00  50.59 MB/s\nr-rlang-0.1.6- 100% |################################| Time: 0:00:00   9.89 MB/s\nr-utf8-1.1.2-m 100% |################################| Time: 0:00:00  48.02 MB/s\nr-bindrcpp-0.2 100% |################################| Time: 0:00:00  17.14 MB/s\nr-bit64-0.9_7- 100% |################################| Time: 0:00:00  49.53 MB/s\nr-cli-1.0.0-mr 100% |################################| Time: 0:00:00  49.70 MB/s\nr-memoise-1.1. 100% |################################| Time: 0:00:00  31.00 MB/s\nr-pillar-1.0.1 100% |################################| Time: 0:00:00  46.28 MB/s\nr-tibble-1.4.1 100% |################################| Time: 0:00:00  49.02 MB/s\nr-blob-1.1.0-m 100% |################################| Time: 0:00:00  23.26 MB/s\nr-dplyr-0.7.4- 100% |################################| Time: 0:00:00  46.50 MB/s\nr-purrr-0.2.4- 100% |################################| Time: 0:00:00  49.74 MB/s\nr-dbplyr-1.1.0 100% |################################| Time: 0:00:00  50.74 MB/s\nr-rsqlite-2.0- 100% |################################| Time: 0:00:00   6.25 MB/s\nrpy2-2.9.1-py3 100% |################################| Time: 0:00:00   2.50 MB/s\n"
                }
            ], 
            "source": "!conda install rpy2"
        }, 
        {
            "source": "## Python analog of R random number functions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: Warning message:\n\n  warnings.warn(x, RRuntimeWarning)\n/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: In doTryCatch(return(expr), name, parentenv, handler) :\n  warnings.warn(x, RRuntimeWarning)\n/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning: \n \n  warnings.warn(x, RRuntimeWarning)\n/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:145: RRuntimeWarning:  unable to load shared object '/opt/conda/envs/DSX-Python35/lib/R/modules//R_X11.so':\n  libXt.so.6: cannot open shared object file: No such file or directory\n\n  warnings.warn(x, RRuntimeWarning)\n"
                }
            ], 
            "source": "%load_ext rpy2.ipython"
        }, 
        {
            "source": "### R functions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%%R\n\nn <- 5\nxs <- c(0.1, 0.5, 0.9)\nprint(dbeta(xs, 0.5, 0.5))\nprint(pbeta(xs, 0.5, 0.5))\nprint(qbeta(xs, 0.5, 0.5))\nprint(rbeta(n, 0.5, 0.5))"
        }, 
        {
            "source": "### Scipy functions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "n = 5\nxs = [0.1, 0.5, 0.9]\nrv = stats.beta(a=0.5, b=0.5)\n\nprint(rv.pdf(xs)) # equivalent of dbeta\nprint(rv.cdf(xs)) # equivalent of pbeta\nprint(rv.ppf(xs)) # equvialent of qbeta\nprint(rv.rvs(n))  # equivalent of rbeta"
        }, 
        {
            "source": "## Why are random numbers useful?\n\nIf we can draw an arbitrary number of random deviates from a distribution, in some sense, we know everyting there is to know about the distribution.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Example \n\nQuestions about IQ assuming a mean of 100 and standard deviaiton of 15.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "\u03bc = 100\n\u03c3 = 15\nn = 10000\nx = np.random.normal(\u03bc, \u03c3, n)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# What fraction of people have IQs greater than 140?\n\nsum(x > 140)/n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# What fraction of people have IQs between 80 and 90?\n\nsum((x > 80) & (x < 90))/n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# What is the average IQ?\n\nsum(x)/n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# What is the median IQ?\n\ny = sorted(x)\n0.5*(y[n//2] + y[n//2+1])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# What IQ do I need to be in the top 5%?\n\ny[int(0.95*n)]"
        }, 
        {
            "source": "## Where do random numbers in the computer come from?\n\nWhile psuedorandom numbers are generated by a deterministic algorithm, we can mostly treat them as if they were true random numbers and we will drop the \"pseudo\" prefix. Fundamentally, the algorithm generates random integers which are then normalized to give a floating point number from the standard uniform distribution. Random numbers from other distributions are in turn generated using these uniform random deviates, either via general (inverse transform, accept/reject, mixture representations) or specialized ad-hoc (e.g. Box-Muller) methods.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Generating standard uniform random numbers", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Linear congruential generators (LCG)\n\n$z_{i+1} = (az_i + c) \\mod m$\n\nHull-Dobell Theorem: The LCG will have a full period for all seeds if and only if\n\n- $c$ and $m$ are relatively prime,\n- $a - 1$ is divisible by all prime factors of $m$\n- $a - 1$ is a multiple of 4 if $m$ is a multiple of 4.\n\nThe number $z_0$ is called the *seed*, and setting it allows us to have a reproducible sequence of \"random\" numbers. The LCG is typically coded to return $z/m$, a floating point number in (0, 1). This can be scaled to any other range $(a, b)$.\n\nNote that most PRNGs now use the [Mersenne twister](http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/ARTICLES/mt.pdf), but the LCG is presented because the LCG code much easier to understand and all we hope for is some appreciation for how apparently random sequences can be generated from a deterministic iterative scheme.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def lcg(m=2**32, a=1103515245, c=12345):\n    lcg.current = (a*lcg.current + c) % m\n    return lcg.current/m"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "# setting the seed\nlcg.current = 1"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "[lcg() for i in range(10)]"
        }, 
        {
            "source": "### Inverse transform method\n\nOnce we have standard uniform numbers, we can often generate random numbers from other distribution using the inverse transform method. Recall that if $X$ is a continuous random variable with CDF $F_X$, then $Y = F_X(X)$ has the standard uniform distribution. Inverting this suggests that if $Y$ comes from a standard uniform distribution, then $F_X^{-1}(Y)$ has the same distribution as $X$. The inverse transform method is used below to generate random numbers from the exponential distribution.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "def expon_pdf(x, lmabd=1):\n    \"\"\"PDF of exponential distribution.\"\"\"\n    return lmabd*np.exp(-lmabd*x)\n\ndef expon_cdf(x, lambd=1):\n    \"\"\"CDF of exponetial distribution.\"\"\"\n    return 1 - np.exp(-lambd*x)\n\ndef expon_icdf(p, lambd=1):\n    \"\"\"Inverse CDF of exponential distribution - i.e. quantile function.\"\"\"\n    return -np.log(1-p)/lambd"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import scipy.stats as stats\n\ndist = stats.expon()\nx = np.linspace(0,4,100)\ny = np.linspace(0,1,100)\n\nwith plt.xkcd():\n    plt.figure(figsize=(12,4))\n    plt.subplot(121)\n    plt.plot(x, expon_cdf(x))\n    plt.axis([0, 4, 0, 1])\n    for q in [0.5, 0.8]:\n        plt.arrow(0, q, expon_icdf(q)-0.1, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n        plt.arrow(expon_icdf(q), q, 0, -q+0.1, head_width=0.1, head_length=0.05, fc='b', ec='b')\n    plt.ylabel('1: Generate a (0,1) uniform PRNG')\n    plt.xlabel('2: Find the inverse CDF')\n    plt.title('Inverse transform method');\n\n    plt.subplot(122)\n    u = np.random.random(10000)\n    v = expon_icdf(u)\n    plt.hist(v, histtype='step', bins=100, normed=True, linewidth=2)\n    plt.plot(x, expon_pdf(x), linewidth=2)\n    plt.axis([0,4,0,1])\n    plt.title('Histogram of exponential PRNGs');"
        }, 
        {
            "source": "#### Inverse transform from sample data\n\nSuppose we have some random samples with an unknown distribution. We can still use the inverse transform method to create a random number generator from a random sample, by estimating the inverse CDF function using interpolation.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from scipy.interpolate import interp1d\nfrom statsmodels.distributions.empirical_distribution import ECDF\n\n# Make up some random data\nx = np.concatenate([np.random.normal(0, 1, 10000), \n                    np.random.normal(4, 1, 10000)])\n\necdf = ECDF(x)\ninv_cdf = interp1d(ecdf.y, ecdf.x, bounds_error=False, assume_sorted=True)\nr = np.random.uniform(0, 1, 1000)\nys = inv_cdf(r)\n\nplt.hist(x, 25, histtype='step', color='red', normed=True, linewidth=1)\nplt.hist(ys, 25, histtype='step', color='blue', normed=True, linewidth=1);"
        }, 
        {
            "source": "### Box-Muller for generating normally distributed random numbers\n\nThe Box-Muller transform starts with 2 random uniform numbers $u$ and $v$\n- Generate an exponentially distributed variable $r^2$ from $u$ using the inverse transform method\n- This means that $r$ is an exponentially distributed variable on $(0, \\infty)$\n- Generate a variable $\\theta$ uniformly distributed on $(0, 2\\pi)$ from $v$ by scaling\n- In polar coordinates, the vector $(r, \\theta)$ has an independent bivariate normal distribution\n- Hence the projection onto the $x$ and $y$ axes give independent univariate normal random numbers\n\nNote:\n\n- Normal random numbers can also be generated using the *general* inverse transform method (e.g. by approximating the inverse CDF with a polynomial) or the rejection method (e.g. using the exponential distribution as the sampling distribution). \n- There is also a variant of Box-Muller that does not require the use of (expensive) trigonometric calculations.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "n = 1000\nu1 = np.random.random(n)\nu2 = np.random.random(n)\nr_squared = -2*np.log(u1)\nr = np.sqrt(r_squared)\ntheta = 2*np.pi*u2\nx = r*np.cos(theta)\ny = r*np.sin(theta)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "g = sns.jointplot(x, y, kind='scatter', xlim=(-3,3), ylim=(-3,3))\npass"
        }, 
        {
            "source": "### Generate univariate random normal deviates", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "@jit(nopython=True)\ndef box_muller(n):\n    \"\"\"Generate n random normal deviates.\"\"\"\n    \n    u1 = np.random.random((n+1)//2)\n    u2 = np.random.random((n+1)//2)\n    r_squared = -2*np.log(u1)\n    r = np.sqrt(r_squared)\n    theta = 2*np.pi*u2\n    x = r*np.cos(theta)\n    y = r*np.sin(theta)\n    z = np.empty(n)\n    z[:((n+1)//2)] = x\n    z[((n+1)//2):] = y\n    return z[:n]"
        }, 
        {
            "source": "### Generating multivariate normal random deviates", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "@jit(nopython=True)\ndef mvn(mu, sigma, n=1):\n    \"\"\"Generate n samples from multivarate normal with mean mu and covariance sigma.\"\"\"\n    \n    A = np.linalg.cholesky(sigma)\n    p = len(mu)\n    \n    zs = np.zeros((n, p))\n    for i in range(n):\n        z = box_muller(p)\n        zs[i] = mu + A@z    \n    return zs"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "mu = 4.0*np.ones(2)\nsigma = np.array([[1,0.6], [0.6, 1]])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "n = 1000\nx, y = mvn(mu, sigma, n).T\ng = sns.jointplot(x, y, kind='scatter')\npass\npass"
        }, 
        {
            "source": "## Rejection sampling", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Suppose we want to sample from the truncated Cauchy distribution \n# We use the uniform as a proposal distibution (highly inefficient)\n\nx = np.linspace(-4, 4)\n\ndist = stats.cauchy()\nupper = dist.pdf(0)\n\nwith plt.xkcd():\n    plt.figure(figsize=(12,4))\n    plt.subplot(121)\n    plt.plot(x, dist.pdf(x))\n    plt.axhline(upper, color='grey')\n    px = 1.0\n    plt.arrow(px,0,0,dist.pdf(1.0)-0.01, linewidth=1,\n              head_width=0.2, head_length=0.01, fc='g', ec='g')\n    plt.arrow(px,upper,0,-(upper-dist.pdf(px)-0.01), linewidth=1, \n              head_width=0.3, head_length=0.01, fc='r', ec='r')\n    plt.text(px+.25, 0.2, 'Reject', fontsize=16)\n    plt.text(px+.25, 0.01, 'Accept', fontsize=16)\n    plt.axis([-4,4,0,0.4])\n    plt.title('Rejection sampling concepts', fontsize=20)\n\n    plt.subplot(122)\n    n = 100000\n    # generate from sampling distribution\n    u = np.random.uniform(-4, 4, n)\n    # accept-reject criterion for each point in sampling distribution\n    r = np.random.uniform(0, upper, n)\n    # accepted points will come from target (Cauchy) distribution\n    v = u[r < dist.pdf(u)]\n\n    plt.plot(x, dist.pdf(x), linewidth=2)\n\n    # Plot scaled histogram \n    factor = dist.cdf(4) - dist.cdf(-4)\n    hist, bin_edges = np.histogram(v, bins=100, normed=True)\n    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.\n    plt.step(bin_centers, factor*hist, linewidth=2)\n\n    plt.axis([-4,4,0,0.4])\n    plt.title('Histogram of accepted samples', fontsize=20);"
        }, 
        {
            "source": "### Mixture representations\n\nSometimes, the target distribution from which we need to generate random numbers can be expressed as a mixture of \"simpler\" distributions that we already know how to sample from\n\n$$\nf(x) = \\int{g(x\\,|\\,y)p(y) dy}\n$$\n\nFor example, if $y$ is drawn from the $\\chi_\\nu^2$ distribution, then $\\mathcal{N}(0, \\nu/y)$ is a sample from the Student's T distribution with $\\nu$ degrees of freedom.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "n = 10000\ndf = 2\ndist = stats.t(df=df)\ny = stats.chi2(df=df).rvs(n)\nr = stats.norm(0, df/y).rvs(n)\n\nwith plt.xkcd():\n    plt.plot(x, dist.pdf(x), linewidth=2)\n\n    # Plot scaled histogram \n    factor = dist.cdf(4) - dist.cdf(-4)\n    hist, bin_edges = np.histogram(v, bins=100, normed=True)\n    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.\n    plt.step(bin_centers, factor*hist, linewidth=2)\n\n    plt.axis([-4,4,0,0.4])\n    plt.title('Histogram of accepted samples', fontsize=20);"
        }, 
        {
            "source": "## Using the `numpy.random` and `scipy.stats` PRNGs\n\nFrom this part onwards, we will assume that there is a library of PRNGs that we can use - either from `numpy.random` or scipy.stats which are both based on the Mersenne Twister, a high-quality PRNG for random integers. The `numpy` versions simply generate random deviates while the `scipy` versions will also provide useful functions related to the distribution, e.g. PDF, CDF and quantiles.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy.random as rng\n\n# Histogram of beta distribution\nrs = rng.beta(a=0.5, b=0.5, size=1000)\nplt.hist(rs, bins=20, histtype='step', normed=True, linewidth=1)\n\n# PDF for the beta distribution\nxs = np.linspace(0, 1, 100)\nplt.plot(xs, stats.beta.pdf(xs, a=0.5, b=0.5), color='red')\npass"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "latex_envs": {
            "current_citInitial": 1, 
            "eqLabelWithNumbers": true, 
            "cite_by": "apalike", 
            "bibliofile": "biblio.bib", 
            "eqNumInitial": 0
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }, 
        "anaconda-cloud": {}
    }, 
    "nbformat": 4
}