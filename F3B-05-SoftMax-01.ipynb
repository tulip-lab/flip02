{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# \u591a\u7c7b\u903b\u8f91\u56de\u5f52 --- \u4ece0\u5f00\u59cb\n\n\u5982\u679c\u4f60\u8bfb\u8fc7\u4e86[\u4ece0\u5f00\u59cb\u7684\u7ebf\u6027\u56de\u5f52](linear-regression-scratch.md)\uff0c\u90a3\u4e48\u6700\u96be\u7684\u90e8\u5206\u5df2\u7ecf\u8fc7\u53bb\u4e86\u3002\u73b0\u5728\u4f60\u77e5\u9053\u5982\u679c\u8bfb\u53d6\u548c\u64cd\u4f5c\u6570\u636e\uff0c\u5982\u4f55\u6784\u9020\u76ee\u6807\u51fd\u6570\u548c\u5bf9\u5b83\u6c42\u5bfc\uff0c\u5982\u679c\u5b9a\u4e49\u635f\u5931\u51fd\u6570\uff0c\u6a21\u578b\u548c\u6c42\u89e3\u3002\n\n\u4e0b\u9762\u6211\u4eec\u6765\u770b\u4e00\u4e2a\u7a0d\u5fae\u6709\u610f\u601d\u4e00\u70b9\u7684\u95ee\u9898\uff0c\u5982\u4f55\u4f7f\u7528\u591a\u7c7b\u903b\u8f91\u56de\u5f52\u8fdb\u884c\u591a\u7c7b\u5206\u7c7b\u3002\u8fd9\u4e2a\u6a21\u578b\u8ddf\u7ebf\u6027\u56de\u5f52\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u8f93\u51fa\u8282\u70b9\u4ece\u4e00\u4e2a\u53d8\u6210\u4e86\u591a\u4e2a\u3002\n\n![](https://github.com/mli/gluon-tutorials-zh/raw/master/img/simple-softmax-net.png)\n\n\n## \u83b7\u53d6\u6570\u636e\n\n\u6f14\u793a\u8fd9\u4e2a\u6a21\u578b\u7684\u5e38\u89c1\u6570\u636e\u96c6\u662f\u624b\u5199\u6570\u5b57\u8bc6\u522bMNIST\uff0c\u5b83\u957f\u8fd9\u4e2a\u6837\u5b50\u3002\n\n![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/example/mnist.png)\n\n\u8fd9\u91cc\u6211\u4eec\u7528\u4e86\u4e00\u4e2a\u7a0d\u5fae\u590d\u6742\u70b9\u7684\u6570\u636e\u96c6\uff0c\u5b83\u8ddfMNIST\u975e\u5e38\u50cf\uff0c\u4f46\u662f\u5185\u5bb9\u4e0d\u518d\u662f\u5206\u7c7b\u6570\u5b57\uff0c\u800c\u662f\u670d\u9970\u3002\u6211\u4eec\u901a\u8fc7gluon\u7684data.vision\u6a21\u5757\u81ea\u52a8\u4e0b\u8f7d\u8fd9\u4e2a\u6570\u636e\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "1"
                }
            }, 
            "outputs": [], 
            "source": "from mxnet import gluon\nfrom mxnet import ndarray as nd\n\ndef transform(data, label):\n    return data.astype('float32')/255, label.astype('float32')\nmnist_train = gluon.data.vision.FashionMNIST(train=True, transform=transform)\nmnist_test = gluon.data.vision.FashionMNIST(train=False, transform=transform)"
        }, 
        {
            "source": "\u6253\u5370\u4e00\u4e2a\u6837\u672c\u7684\u5f62\u72b6\u548c\u5b83\u7684\u6807\u53f7", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "2"
                }
            }, 
            "outputs": [], 
            "source": "data, label = mnist_train[0]\n('example shape: ', data.shape, 'label:', label)"
        }, 
        {
            "source": "\u6211\u4eec\u753b\u51fa\u524d\u51e0\u4e2a\u6837\u672c\u7684\u5185\u5bb9\uff0c\u548c\u5bf9\u5e94\u7684\u6587\u672c\u6807\u53f7", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "3"
                }
            }, 
            "outputs": [], 
            "source": "import matplotlib.pyplot as plt\n\ndef show_images(images):\n    n = images.shape[0]\n    _, figs = plt.subplots(1, n, figsize=(15, 15))\n    for i in range(n):\n        figs[i].imshow(images[i].reshape((28, 28)).asnumpy())\n        figs[i].axes.get_xaxis().set_visible(False)\n        figs[i].axes.get_yaxis().set_visible(False)\n    plt.show()\n\ndef get_text_labels(label):\n    text_labels = [\n        't-shirt', 'trouser', 'pullover', 'dress,', 'coat',\n        'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'\n    ]\n    return [text_labels[int(i)] for i in label]\n\ndata, label = mnist_train[0:9]\nshow_images(data)\nprint(get_text_labels(label))"
        }, 
        {
            "source": "## \u6570\u636e\u8bfb\u53d6\n\n\u867d\u7136\u6211\u4eec\u53ef\u4ee5\u50cf\u524d\u9762\u90a3\u6837\u901a\u8fc7`yield`\u6765\u5b9a\u4e49\u83b7\u53d6\u6279\u91cf\u6570\u636e\u51fd\u6570\uff0c\u8fd9\u91cc\u6211\u4eec\u76f4\u63a5\u4f7f\u7528gluon.data\u7684DataLoader\u51fd\u6570\uff0c\u5b83\u6bcf\u6b21`yield`\u4e00\u4e2a\u6279\u91cf\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "4"
                }
            }, 
            "outputs": [], 
            "source": "batch_size = 256\ntrain_data = gluon.data.DataLoader(mnist_train, batch_size, shuffle=True)\ntest_data = gluon.data.DataLoader(mnist_test, batch_size, shuffle=False)"
        }, 
        {
            "source": "\u6ce8\u610f\u5230\u8fd9\u91cc\u6211\u4eec\u8981\u6c42\u6bcf\u6b21\u4ece\u8bad\u7ec3\u6570\u636e\u91cc\u8bfb\u53d6\u4e00\u4e2a\u7531\u968f\u673a\u6837\u672c\u7ec4\u6210\u7684\u6279\u91cf\uff0c\u4f46\u6d4b\u8bd5\u6570\u636e\u5219\u4e0d\u9700\u8981\u8fd9\u4e2a\u8981\u6c42\u3002\n\n## \u521d\u59cb\u5316\u6a21\u578b\u53c2\u6570\n\n\u8ddf\u7ebf\u6027\u6a21\u578b\u4e00\u6837\uff0c\u6bcf\u4e2a\u6837\u672c\u4f1a\u8868\u793a\u6210\u4e00\u4e2a\u5411\u91cf\u3002\u6211\u4eec\u8fd9\u91cc\u6570\u636e\u662f 28 * 28 \u5927\u5c0f\u7684\u56fe\u7247\uff0c\u6240\u4ee5\u8f93\u5165\u5411\u91cf\u7684\u957f\u5ea6\u662f 28 * 28 = 784\u3002\u56e0\u4e3a\u6211\u4eec\u8981\u505a\u591a\u7c7b\u5206\u7c7b\uff0c\u6211\u4eec\u9700\u8981\u5bf9\u6bcf\u4e00\u4e2a\u7c7b\u9884\u6d4b\u8fd9\u4e2a\u6837\u672c\u5c5e\u4e8e\u6b64\u7c7b\u7684\u6982\u7387\u3002\u56e0\u4e3a\u8fd9\u4e2a\u6570\u636e\u96c6\u670910\u4e2a\u7c7b\u578b\uff0c\u6240\u4ee5\u8f93\u51fa\u5e94\u8be5\u662f\u957f\u4e3a10\u7684\u5411\u91cf\u3002\u8fd9\u6837\uff0c\u6211\u4eec\u9700\u8981\u7684\u6743\u91cd\u5c06\u662f\u4e00\u4e2a 784 * 10 \u7684\u77e9\u9635\uff1a", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "5"
                }
            }, 
            "outputs": [], 
            "source": "num_inputs = 784\nnum_outputs = 10\n\nW = nd.random_normal(shape=(num_inputs, num_outputs))\nb = nd.random_normal(shape=num_outputs)\n\nparams = [W, b]"
        }, 
        {
            "source": "\u540c\u4e4b\u524d\u4e00\u6837\uff0c\u6211\u4eec\u8981\u5bf9\u6a21\u578b\u53c2\u6570\u9644\u4e0a\u68af\u5ea6\uff1a", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "6"
                }
            }, 
            "outputs": [], 
            "source": "for param in params:\n    param.attach_grad()"
        }, 
        {
            "source": "## \u5b9a\u4e49\u6a21\u578b\n\n\u5728\u7ebf\u6027\u56de\u5f52\u6559\u7a0b\u91cc\uff0c\u6211\u4eec\u53ea\u9700\u8981\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf`yhat`\u4f7f\u5f97\u5c3d\u53ef\u80fd\u7684\u9760\u8fd1\u76ee\u6807\u503c\u3002\u4f46\u5728\u8fd9\u91cc\u7684\u5206\u7c7b\u91cc\uff0c\u6211\u4eec\u9700\u8981\u5c5e\u4e8e\u6bcf\u4e2a\u7c7b\u522b\u7684\u6982\u7387\u3002\u8fd9\u4e9b\u6982\u7387\u9700\u8981\u503c\u4e3a\u6b63\uff0c\u800c\u4e14\u52a0\u8d77\u6765\u7b49\u4e8e1. \u800c\u5982\u679c\u7b80\u5355\u7684\u4f7f\u7528 $\\boldsymbol{\\hat y} = \\boldsymbol{W} \\boldsymbol{x}$, \u6211\u4eec\u4e0d\u80fd\u4fdd\u8bc1\u8fd9\u4e00\u70b9\u3002\u4e00\u4e2a\u901a\u5e38\u7684\u505a\u6cd5\u662f\u901a\u8fc7softmax\u51fd\u6570\u6765\u5c06\u4efb\u610f\u7684\u8f93\u5165\u5f52\u4e00\u5316\u6210\u5408\u6cd5\u7684\u6982\u7387\u503c\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "7"
                }
            }, 
            "outputs": [], 
            "source": "from mxnet import nd\ndef softmax(X):\n    exp = nd.exp(X)\n    # \u5047\u8bbeexp\u662f\u77e9\u9635\uff0c\u8fd9\u91cc\u5bf9\u884c\u8fdb\u884c\u6c42\u548c\uff0c\u5e76\u8981\u6c42\u4fdd\u7559axis 1\uff0c\n    # \u5c31\u662f\u8fd4\u56de (nrows, 1) \u5f62\u72b6\u7684\u77e9\u9635\n    partition = exp.sum(axis=1, keepdims=True)\n    return exp / partition"
        }, 
        {
            "source": "\u53ef\u4ee5\u770b\u5230\uff0c\u5bf9\u4e8e\u968f\u673a\u8f93\u5165\uff0c\u6211\u4eec\u5c06\u6bcf\u4e2a\u5143\u7d20\u53d8\u6210\u4e86\u975e\u8d1f\u6570\uff0c\u800c\u4e14\u6bcf\u4e00\u884c\u52a0\u8d77\u6765\u4e3a1\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "8"
                }
            }, 
            "outputs": [], 
            "source": "X = nd.random_normal(shape=(2,5))\nX_prob = softmax(X)\nprint(X)\nprint('Normalized Prob:' , X_prob)\nprint(X_prob.sum(axis=1))"
        }, 
        {
            "source": "\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\u6a21\u578b\u4e86\uff1a", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "9"
                }
            }, 
            "outputs": [], 
            "source": "def net(X):\n    return softmax(nd.dot(X.reshape((-1,num_inputs)), W) + b)"
        }, 
        {
            "source": "## \u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\n\n\u6211\u4eec\u9700\u8981\u5b9a\u4e49\u4e00\u4e2a\u9488\u5bf9\u9884\u6d4b\u4e3a\u6982\u7387\u503c\u7684\u635f\u5931\u51fd\u6570\u3002\u5176\u4e2d\u6700\u5e38\u89c1\u7684\u662f\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u5b83\u5c06\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u7684\u8d1f\u4ea4\u53c9\u71b5\u4f5c\u4e3a\u76ee\u6807\u503c\uff0c\u6700\u5c0f\u5316\u8fd9\u4e2a\u503c\u7b49\u4ef7\u4e8e\u6700\u5927\u5316\u8fd9\u4e24\u4e2a\u6982\u7387\u7684\u76f8\u4f3c\u5ea6\u3002\n\n\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5148\u5c06\u771f\u5b9e\u6807\u53f7\u8868\u793a\u6210\u4e00\u4e2a\u6982\u7387\u5206\u5e03\uff0c\u4f8b\u5982\u5982\u679c`y=1`\uff0c\u90a3\u4e48\u5176\u5bf9\u5e94\u7684\u5206\u5e03\u5c31\u662f\u4e00\u4e2a\u9664\u4e86\u7b2c\u4e8c\u4e2a\u5143\u7d20\u4e3a1\u5176\u4ed6\u5168\u4e3a0\u7684\u957f\u4e3a10\u7684\u5411\u91cf\uff0c\u4e5f\u5c31\u662f `yvec=[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]`\u3002\u90a3\u4e48\u4ea4\u53c9\u71b5\u5c31\u662f`yvec[0]*log(yhat[0])+...+yvec[n]*log(yhat[n])`\u3002\u6ce8\u610f\u5230`yvec`\u91cc\u9762\u53ea\u6709\u4e00\u4e2a1\uff0c\u90a3\u4e48\u524d\u9762\u7b49\u4ef7\u4e8e`log(yhat[y])`\u3002\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u4e86", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "10"
                }
            }, 
            "outputs": [], 
            "source": "def cross_entropy(yhat, y):\n    return - nd.pick(nd.log(yhat), y)"
        }, 
        {
            "source": "## \u8ba1\u7b97\u7cbe\u5ea6\n\n\u7ed9\u5b9a\u4e00\u4e2a\u6982\u7387\u8f93\u51fa\uff0c\u6211\u4eec\u5c06\u9884\u6d4b\u6982\u7387\u6700\u9ad8\u7684\u90a3\u4e2a\u7c7b\u4f5c\u4e3a\u9884\u6d4b\u7684\u7c7b\uff0c\u7136\u540e\u901a\u8fc7\u6bd4\u8f83\u771f\u5b9e\u6807\u53f7\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u7cbe\u5ea6\uff1a", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "12"
                }
            }, 
            "outputs": [], 
            "source": "def accuracy(output, label):\n    return nd.mean(output.argmax(axis=1)==label).asscalar()"
        }, 
        {
            "source": "\u6211\u4eec\u53ef\u4ee5\u8bc4\u4f30\u4e00\u4e2a\u6a21\u578b\u5728\u8fd9\u4e2a\u6570\u636e\u4e0a\u7684\u7cbe\u5ea6\u3002\uff08\u8fd9\u4e24\u4e2a\u51fd\u6570\u6211\u4eec\u4e4b\u540e\u4e5f\u4f1a\u7528\u5230\uff0c\u6240\u4ee5\u4e5f\u90fd\u4fdd\u5b58\u5728[../utils.py](../utils.py)\u3002\uff09", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "13"
                }
            }, 
            "outputs": [], 
            "source": "def evaluate_accuracy(data_iterator, net):\n    acc = 0.\n    for data, label in data_iterator:\n        output = net(data)\n        acc += accuracy(output, label)\n    return acc / len(data_iterator)"
        }, 
        {
            "source": "\u56e0\u4e3a\u6211\u4eec\u968f\u673a\u521d\u59cb\u5316\u4e86\u6a21\u578b\uff0c\u6240\u4ee5\u8fd9\u4e2a\u6a21\u578b\u7684\u7cbe\u5ea6\u5e94\u8be5\u5927\u6982\u662f`1/num_outputs = 0.1`.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "14"
                }
            }, 
            "outputs": [], 
            "source": "evaluate_accuracy(test_data, net)"
        }, 
        {
            "source": "## \u8bad\u7ec3\n\n\u8bad\u7ec3\u4ee3\u7801\u8ddf\u524d\u9762\u7684\u7ebf\u6027\u56de\u5f52\u975e\u5e38\u76f8\u4f3c\uff1a", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!rm utils*\n!wget https://github.com/mli/gluon-tutorials-zh/raw/master/utils.py"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ls\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import urllib\nresponse = urllib.urlopen('https://github.com/mli/gluon-tutorials-zh/raw/master/utils.py')\ncontent = response.read()\ntarget = open('utils.py', 'w')\n\ntarget.write(content)\ntarget.close()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# %load utils.py\nfrom math import exp\nfrom mxnet import gluon\nfrom mxnet import autograd\nfrom mxnet import nd\nfrom mxnet import image\nfrom mxnet.gluon import nn\nimport mxnet as mx\nimport numpy as np\nfrom time import time\nimport matplotlib.pyplot as plt\n\nclass DataLoader(object):\n    \"\"\"similiar to gluon.data.DataLoader, but might be faster.\n\n    The main difference this data loader tries to read more exmaples each\n    time. But the limits are 1) all examples in dataset have the same shape, 2)\n    data transfomer needs to process multiple examples at each time\n    \"\"\"\n    def __init__(self, dataset, batch_size, shuffle, transform=None):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.transform = transform\n\n    def __iter__(self):\n        data = self.dataset[:]\n        X = data[0]\n        y = nd.array(data[1])\n        n = X.shape[0]\n        if self.shuffle:\n            idx = np.arange(n)\n            np.random.shuffle(idx)\n            X = nd.array(X.asnumpy()[idx])\n            y = nd.array(y.asnumpy()[idx])\n\n        for i in range(n//self.batch_size):\n            if self.transform is not None:\n                yield self.transform(X[i*self.batch_size:(i+1)*self.batch_size], \n                                     y[i*self.batch_size:(i+1)*self.batch_size])\n            else:\n                yield (X[i*self.batch_size:(i+1)*self.batch_size],\n                       y[i*self.batch_size:(i+1)*self.batch_size])\n\n    def __len__(self):\n        return len(self.dataset)//self.batch_size\n\ndef load_data_fashion_mnist(batch_size, resize=None, root=\"~/.mxnet/datasets/fashion-mnist\"):\n    \"\"\"download the fashion mnist dataest and then load into memory\"\"\"\n    def transform_mnist(data, label):\n        # Transform a batch of examples.\n        if resize:\n            n = data.shape[0]\n            new_data = nd.zeros((n, resize, resize, data.shape[3]))\n            for i in range(n):\n                new_data[i] = image.imresize(data[i], resize, resize)\n            data = new_data\n        # change data from batch x height x width x channel to batch x channel x height x width\n        return nd.transpose(data.astype('float32'), (0,3,1,2))/255, label.astype('float32')\n\n    mnist_train = gluon.data.vision.FashionMNIST(root=root, train=True, transform=None)\n    mnist_test = gluon.data.vision.FashionMNIST(root=root, train=False, transform=None)\n    # Transform later to avoid memory explosion. \n    train_data = DataLoader(mnist_train, batch_size, shuffle=True, transform=transform_mnist)\n    test_data = DataLoader(mnist_test, batch_size, shuffle=False, transform=transform_mnist)\n    return (train_data, test_data)\n\ndef try_gpu():\n    \"\"\"If GPU is available, return mx.gpu(0); else return mx.cpu()\"\"\"\n    try:\n        ctx = mx.gpu()\n        _ = nd.array([0], ctx=ctx)\n    except:\n        ctx = mx.cpu()\n    return ctx\n\ndef try_all_gpus():\n    \"\"\"Return all available GPUs, or [mx.gpu()] if there is no GPU\"\"\"\n    ctx_list = []\n    try:\n        for i in range(16):\n            ctx = mx.gpu(i)\n            _ = nd.array([0], ctx=ctx)\n            ctx_list.append(ctx)\n    except:\n        pass\n    if not ctx_list:\n        ctx_list = [mx.cpu()]\n    return ctx_list\n\ndef SGD(params, lr):\n    for param in params:\n        param[:] = param - lr * param.grad\n\ndef accuracy(output, label):\n    return nd.mean(output.argmax(axis=1)==label).asscalar()\n\ndef _get_batch(batch, ctx):\n    \"\"\"return data and label on ctx\"\"\"\n    if isinstance(batch, mx.io.DataBatch):\n        data = batch.data[0]\n        label = batch.label[0]\n    else:\n        data, label = batch\n    return (gluon.utils.split_and_load(data, ctx),\n            gluon.utils.split_and_load(label, ctx),\n            data.shape[0])\n\ndef evaluate_accuracy(data_iterator, net, ctx=[mx.cpu()]):\n    if isinstance(ctx, mx.Context):\n        ctx = [ctx]\n    acc = nd.array([0])\n    n = 0.\n    if isinstance(data_iterator, mx.io.MXDataIter):\n        data_iterator.reset()\n    for batch in data_iterator:\n        data, label, batch_size = _get_batch(batch, ctx)\n        for X, y in zip(data, label):\n            acc += nd.sum(net(X).argmax(axis=1)==y).copyto(mx.cpu())\n            n += y.size\n        acc.wait_to_read() # don't push too many operators into backend\n    return acc.asscalar() / n\n\ndef train(train_data, test_data, net, loss, trainer, ctx, num_epochs, print_batches=None):\n    \"\"\"Train a network\"\"\"\n    print(\"Start training on \", ctx)\n    if isinstance(ctx, mx.Context):\n        ctx = [ctx]\n    for epoch in range(num_epochs):\n        train_loss, train_acc, n, m = 0.0, 0.0, 0.0, 0.0\n        if isinstance(train_data, mx.io.MXDataIter):\n            train_data.reset()\n        start = time()\n        for i, batch in enumerate(train_data):\n            data, label, batch_size = _get_batch(batch, ctx)\n            losses = []\n            with autograd.record():\n                outputs = [net(X) for X in data]\n                losses = [loss(yhat, y) for yhat, y in zip(outputs, label)]\n            for l in losses:\n                l.backward()\n            train_acc += sum([(yhat.argmax(axis=1)==y).sum().asscalar()\n                              for yhat, y in zip(outputs, label)])\n            train_loss += sum([l.sum().asscalar() for l in losses])\n            trainer.step(batch_size)\n            n += batch_size\n            m += sum([y.size for y in label])\n            if print_batches and (i+1) % print_batches == 0:\n                print(\"Batch %d. Loss: %f, Train acc %f\" % (\n                    n, train_loss/n, train_acc/m\n                ))\n\n        test_acc = evaluate_accuracy(test_data, net, ctx)\n        print(\"Epoch %d. Loss: %.3f, Train acc %.2f, Test acc %.2f, Time %.1f sec\" % (\n            epoch, train_loss/n, train_acc/m, test_acc, time() - start\n        ))\n\nclass Residual(nn.HybridBlock):\n    def __init__(self, channels, same_shape=True, **kwargs):\n        super(Residual, self).__init__(**kwargs)\n        self.same_shape = same_shape\n        with self.name_scope():\n            strides = 1 if same_shape else 2\n            self.conv1 = nn.Conv2D(channels, kernel_size=3, padding=1,\n                                  strides=strides)\n            self.bn1 = nn.BatchNorm()\n            self.conv2 = nn.Conv2D(channels, kernel_size=3, padding=1)\n            self.bn2 = nn.BatchNorm()\n            if not same_shape:\n                self.conv3 = nn.Conv2D(channels, kernel_size=1,\n                                      strides=strides)\n\n    def hybrid_forward(self, F, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        if not self.same_shape:\n            x = self.conv3(x)\n        return F.relu(out + x)\n\ndef resnet18(num_classes):\n    net = nn.HybridSequential()\n    with net.name_scope():\n        net.add(\n            nn.BatchNorm(),\n            nn.Conv2D(64, kernel_size=3, strides=1),\n            nn.MaxPool2D(pool_size=3, strides=2),\n            Residual(64),\n            Residual(64),\n            Residual(128, same_shape=False),\n            Residual(128),\n            Residual(256, same_shape=False),\n            Residual(256),\n            nn.GlobalAvgPool2D(),\n            nn.Dense(num_classes)\n        )\n    return net\n\ndef show_images(imgs, nrows, ncols, figsize=None):\n    \"\"\"plot a list of images\"\"\"\n    if not figsize:\n        figsize = (ncols, nrows)\n    _, figs = plt.subplots(nrows, ncols, figsize=figsize)\n    for i in range(nrows):\n        for j in range(ncols):\n            figs[i][j].imshow(imgs[i*ncols+j].asnumpy())\n            figs[i][j].axes.get_xaxis().set_visible(False)\n            figs[i][j].axes.get_yaxis().set_visible(False)\n    plt.show()\n\ndef data_iter_random(corpus_indices, batch_size, num_steps, ctx=None):\n    \"\"\"Sample mini-batches in a random order from sequential data.\"\"\"\n    # Subtract 1 because label indices are corresponding input indices + 1. \n    num_examples = (len(corpus_indices) - 1) // num_steps\n    epoch_size = num_examples // batch_size\n    # Randomize samples.\n    example_indices = list(range(num_examples))\n    random.shuffle(example_indices)\n\n    def _data(pos):\n        return corpus_indices[pos: pos + num_steps]\n\n    for i in range(epoch_size):\n        # Read batch_size random samples each time.\n        i = i * batch_size\n        batch_indices = example_indices[i: i + batch_size]\n        data = nd.array(\n            [_data(j * num_steps) for j in batch_indices], ctx=ctx)\n        label = nd.array(\n            [_data(j * num_steps + 1) for j in batch_indices], ctx=ctx)\n        yield data, label\n\ndef data_iter_consecutive(corpus_indices, batch_size, num_steps, ctx=None):\n    \"\"\"Sample mini-batches in a consecutive order from sequential data.\"\"\"\n    corpus_indices = nd.array(corpus_indices, ctx=ctx)\n    data_len = len(corpus_indices)\n    batch_len = data_len // batch_size\n    \n    indices = corpus_indices[0: batch_size * batch_len].reshape((\n        batch_size, batch_len))\n    # Subtract 1 because label indices are corresponding input indices + 1. \n    epoch_size = (batch_len - 1) // num_steps\n    \n    for i in range(epoch_size):\n        i = i * num_steps\n        data = indices[:, i: i + num_steps]\n        label = indices[:, i + 1: i + num_steps + 1]\n        yield data, label\n\n\ndef grad_clipping(params, clipping_norm, ctx):\n    \"\"\"Gradient clipping.\"\"\"\n    if clipping_norm is not None:\n        norm = nd.array([0.0], ctx)\n        for p in params:\n            norm += nd.sum(p.grad ** 2)\n        norm = nd.sqrt(norm).asscalar()\n        if norm > clipping_norm:\n            for p in params:\n                p.grad[:] *= clipping_norm / norm\n\n\ndef predict_rnn(rnn, prefix, num_chars, params, hidden_dim, ctx, idx_to_char,\n                char_to_idx, get_inputs, is_lstm=False):\n    \"\"\"Predict the next chars given the prefix.\"\"\"\n    prefix = prefix.lower()\n    state_h = nd.zeros(shape=(1, hidden_dim), ctx=ctx)\n    if is_lstm:\n        state_c = nd.zeros(shape=(1, hidden_dim), ctx=ctx)\n    output = [char_to_idx[prefix[0]]]\n    for i in range(num_chars + len(prefix)):\n        X = nd.array([output[-1]], ctx=ctx)\n        if is_lstm:\n            Y, state_h, state_c = rnn(get_inputs(X), state_h, state_c, *params)\n        else:\n            Y, state_h = rnn(get_inputs(X), state_h, *params)\n        if i < len(prefix)-1:\n            next_input = char_to_idx[prefix[i+1]]\n        else:\n            next_input = int(Y[0].argmax(axis=1).asscalar())\n        output.append(next_input)\n    return ''.join([idx_to_char[i] for i in output])\n\n\ndef train_and_predict_rnn(rnn, is_random_iter, epochs, num_steps, hidden_dim, \n                          learning_rate, clipping_norm, batch_size,\n                          pred_period, pred_len, seqs, get_params, get_inputs,\n                          ctx, corpus_indices, idx_to_char, char_to_idx,\n                          is_lstm=False):\n    \"\"\"Train an RNN model and predict the next item in the sequence.\"\"\"\n    if is_random_iter:\n        data_iter = data_iter_random\n    else:\n        data_iter = data_iter_consecutive\n    params = get_params()\n    \n    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n\n    for e in range(1, epochs + 1): \n        # If consecutive sampling is used, in the same epoch, the hidden state\n        # is initialized only at the beginning of the epoch.\n        if not is_random_iter:\n            state_h = nd.zeros(shape=(batch_size, hidden_dim), ctx=ctx)\n            if is_lstm:\n                state_c = nd.zeros(shape=(batch_size, hidden_dim), ctx=ctx)\n        train_loss, num_examples = 0, 0\n        for data, label in data_iter(corpus_indices, batch_size, num_steps, \n                                     ctx):\n            # If random sampling is used, the hidden state has to be\n            # initialized for each mini-batch.\n            if is_random_iter:\n                state_h = nd.zeros(shape=(batch_size, hidden_dim), ctx=ctx)\n                if is_lstm:\n                    state_c = nd.zeros(shape=(batch_size, hidden_dim), ctx=ctx)\n            with autograd.record():\n                # outputs shape: (batch_size, vocab_size)\n                if is_lstm:\n                    outputs, state_h, state_c = rnn(get_inputs(data), state_h,\n                                                    state_c, *params) \n                else:\n                    outputs, state_h = rnn(get_inputs(data), state_h, *params)\n                # Let t_ib_j be the j-th element of the mini-batch at time i.\n                # label shape: (batch_size * num_steps)\n                # label = [t_0b_0, t_0b_1, ..., t_1b_0, t_1b_1, ..., ].\n                label = label.T.reshape((-1,))\n                # Concatenate outputs:\n                # shape: (batch_size * num_steps, vocab_size).\n                outputs = nd.concat(*outputs, dim=0)\n                # Now outputs and label are aligned.\n                loss = softmax_cross_entropy(outputs, label)\n            loss.backward()\n\n            grad_clipping(params, clipping_norm, ctx)\n            SGD(params, learning_rate)\n\n            train_loss += nd.sum(loss).asscalar()\n            num_examples += loss.size\n\n        if e % pred_period == 0:\n            print(\"Epoch %d. Training perplexity %f\" % (e, \n                                               exp(train_loss/num_examples)))\n            for seq in seqs:\n                print(' - ', predict_rnn(rnn, seq, pred_len, params,\n                      hidden_dim, ctx, idx_to_char, char_to_idx, get_inputs,\n                      is_lstm))\n            print()\n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "3"
                }
            }, 
            "outputs": [], 
            "source": "import sys\nsys.path.append('..')\nfrom utils import SGD\nfrom mxnet import autograd\n\n\nlearning_rate = .1\n\nfor epoch in range(5):\n    train_loss = 0.\n    train_acc = 0.\n    for data, label in train_data:\n        with autograd.record():\n            output = net(data)\n            loss = cross_entropy(output, label)\n        loss.backward()\n        # \u5c06\u68af\u5ea6\u505a\u5e73\u5747\uff0c\u8fd9\u6837\u5b66\u4e60\u7387\u4f1a\u5bf9batch size\u4e0d\u90a3\u4e48\u654f\u611f\n        SGD(params, learning_rate/batch_size)\n\n        train_loss += nd.mean(loss).asscalar()\n        train_acc += accuracy(output, label)\n\n    test_acc = evaluate_accuracy(test_data, net)\n    print(\"Epoch %d. Loss: %f, Train acc %f, Test acc %f\" % (\n        epoch, train_loss/len(train_data), train_acc/len(train_data), test_acc))"
        }, 
        {
            "source": "## \u9884\u6d4b\n\n\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u73b0\u5728\u6211\u4eec\u53ef\u4ee5\u6f14\u793a\u5bf9\u8f93\u5165\u56fe\u7247\u7684\u6807\u53f7\u7684\u9884\u6d4b", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!wget https://github.com/mli/gluon-tutorials-zh/blob/master/utils.py"
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import urllib\nresponse = urllib.urlopen('https://github.com/mli/gluon-tutorials-zh/blob/master/utils.py')\ncontent = response.read()\ntarget = open('utils2.py', 'w')\ntarget.write(content)\ntarget.close()"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "apache_access_log-beaa3.PROJECT  MNIST_data\t\tshakespeare (1).txt\r\nbrain_body_data.csv\t\t models\t\t\tshakespeare.txt\r\ndata.npy\t\t\t moviedataset.zip\tsimple-examples.tgz\r\ndatasets\t\t\t mtcars (1).csv\t\tsummary_logs\r\ndl\t\t\t\t mtcars.csv\t\ttf_logs\r\nkdd.gz\t\t\t\t PierceCricketData.csv\tutils2.py\r\nlangmod\t\t\t\t ptb.zip\t\tutils.py\r\nlena (2).png\t\t\t reader.pyc\t\tvocab.pkl\r\nlena.png\t\t\t recsys\r\n"
                }
            ], 
            "source": "!ls"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# %load utils.py\n\"\"\" This file contains different utility functions that are not connected\nin anyway to the networks presented in the tutorials, but rather help in\nprocessing the outputs into a more understandable way.\n\nFor example ``tile_raster_images`` helps in generating a easy to grasp\nimage from a set of samples or weights.\n\"\"\"\n\nimport numpy\n\n\ndef scale_to_unit_interval(ndar, eps=1e-8):\n    \"\"\" Scales all values in the ndarray ndar to be between 0 and 1 \"\"\"\n    ndar = ndar.copy()\n    ndar -= ndar.min()\n    ndar *= 1.0 / (ndar.max() + eps)\n    return ndar\n\n\ndef tile_raster_images(X, img_shape, tile_shape, tile_spacing=(0, 0),\n                       scale_rows_to_unit_interval=True,\n                       output_pixel_vals=True):\n    \"\"\"\n    Transform an array with one flattened image per row, into an array in\n    which images are reshaped and layed out like tiles on a floor.\n\n    This function is useful for visualizing datasets whose rows are images,\n    and also columns of matrices for transforming those rows\n    (such as the first layer of a neural net).\n\n    :type X: a 2-D ndarray or a tuple of 4 channels, elements of which can\n    be 2-D ndarrays or None;\n    :param X: a 2-D array in which every row is a flattened image.\n\n    :type img_shape: tuple; (height, width)\n    :param img_shape: the original shape of each image\n\n    :type tile_shape: tuple; (rows, cols)\n    :param tile_shape: the number of images to tile (rows, cols)\n\n    :param output_pixel_vals: if output should be pixel values (i.e. int8\n    values) or floats\n\n    :param scale_rows_to_unit_interval: if the values need to be scaled before\n    being plotted to [0,1] or not\n\n\n    :returns: array suitable for viewing as an image.\n    (See:`Image.fromarray`.)\n    :rtype: a 2-d array with same dtype as X.\n\n    \"\"\"\n\n    assert len(img_shape) == 2\n    assert len(tile_shape) == 2\n    assert len(tile_spacing) == 2\n\n    # The expression below can be re-written in a more C style as\n    # follows :\n    #\n    # out_shape    = [0,0]\n    # out_shape[0] = (img_shape[0]+tile_spacing[0])*tile_shape[0] -\n    #                tile_spacing[0]\n    # out_shape[1] = (img_shape[1]+tile_spacing[1])*tile_shape[1] -\n    #                tile_spacing[1]\n    out_shape = [\n        (ishp + tsp) * tshp - tsp\n        for ishp, tshp, tsp in zip(img_shape, tile_shape, tile_spacing)\n    ]\n\n    if isinstance(X, tuple):\n        assert len(X) == 4\n        # Create an output numpy ndarray to store the image\n        if output_pixel_vals:\n            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),\n                                    dtype='uint8')\n        else:\n            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),\n                                    dtype=X.dtype)\n\n        #colors default to 0, alpha defaults to 1 (opaque)\n        if output_pixel_vals:\n            channel_defaults = [0, 0, 0, 255]\n        else:\n            channel_defaults = [0., 0., 0., 1.]\n\n        for i in range(4):\n            if X[i] is None:\n                # if channel is None, fill it with zeros of the correct\n                # dtype\n                dt = out_array.dtype\n                if output_pixel_vals:\n                    dt = 'uint8'\n                out_array[:, :, i] = numpy.zeros(\n                    out_shape,\n                    dtype=dt\n                ) + channel_defaults[i]\n            else:\n                # use a recurrent call to compute the channel and store it\n                # in the output\n                out_array[:, :, i] = tile_raster_images(\n                    X[i], img_shape, tile_shape, tile_spacing,\n                    scale_rows_to_unit_interval, output_pixel_vals)\n        return out_array\n\n    else:\n        # if we are dealing with only one channel\n        H, W = img_shape\n        Hs, Ws = tile_spacing\n\n        # generate a matrix to store the output\n        dt = X.dtype\n        if output_pixel_vals:\n            dt = 'uint8'\n        out_array = numpy.zeros(out_shape, dtype=dt)\n\n        for tile_row in range(tile_shape[0]):\n            for tile_col in range(tile_shape[1]):\n                if tile_row * tile_shape[1] + tile_col < X.shape[0]:\n                    this_x = X[tile_row * tile_shape[1] + tile_col]\n                    if scale_rows_to_unit_interval:\n                        # if we should scale values to be between 0 and 1\n                        # do this by calling the `scale_to_unit_interval`\n                        # function\n                        this_img = scale_to_unit_interval(\n                            this_x.reshape(img_shape))\n                    else:\n                        this_img = this_x.reshape(img_shape)\n                    # add the slice to the corresponding position in the\n                    # output array\n                    c = 1\n                    if output_pixel_vals:\n                        c = 255\n                    out_array[\n                        tile_row * (H + Hs): tile_row * (H + Hs) + H,\n                        tile_col * (W + Ws): tile_col * (W + Ws) + W\n                    ] = this_img * c\n        return out_array\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import sys\nsys.path.append('..')\n#from utils import SGD\nfrom mxnet import autograd\n\nlearning_rate = .1\n\nfor epoch in range(5):\n    train_loss = 0.\n    train_acc = 0.\n    for data, label in train_data:\n        with autograd.record():\n            output = net(data)\n            loss = cross_entropy(output, label)\n        loss.backward()\n        # \u5c06\u68af\u5ea6\u505a\u5e73\u5747\uff0c\u8fd9\u6837\u5b66\u4e60\u7387\u4f1a\u5bf9batch size\u4e0d\u90a3\u4e48\u654f\u611f\n        SGD(params, learning_rate/batch_size)\n\n        train_loss += nd.mean(loss).asscalar()\n        train_acc += accuracy(output, label)\n\n    test_acc = evaluate_accuracy(test_data, net)\n    print(\"Epoch %d. Loss: %f, Train acc %f, Test acc %f\" % (\n        epoch, train_loss/len(train_data), train_acc/len(train_data), test_acc))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "16"
                }
            }, 
            "outputs": [], 
            "source": "data, label = mnist_test[0:9]\nshow_images(data)\nprint('true labels')\nprint(get_text_labels(label))\n\npredicted_labels = net(data).argmax(axis=1)\nprint('predicted labels')\nprint(get_text_labels(predicted_labels.asnumpy()))"
        }, 
        {
            "source": "## \u7ed3\u8bba\n\n\u4e0e\u524d\u9762\u7684\u7ebf\u6027\u56de\u5f52\u76f8\u6bd4\uff0c\u4f60\u4f1a\u53d1\u73b0\u591a\u7c7b\u903b\u8f91\u56de\u5f52\u6559\u7a0b\u7684\u7ed3\u6784\u8ddf\u5176\u975e\u5e38\u76f8\u4f3c\uff1a\u83b7\u53d6\u6570\u636e\u3001\u5b9a\u4e49\u6a21\u578b\u53ca\u4f18\u5316\u7b97\u6cd5\u548c\u6c42\u89e3\u3002\u4e8b\u5b9e\u4e0a\uff0c\u51e0\u4e4e\u6240\u6709\u7684\u5b9e\u9645\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u90fd\u6709\u7740\u540c\u6837\u7ed3\u6784\u3002\u4ed6\u4eec\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u6a21\u578b\u7684\u7c7b\u578b\u548c\u6570\u636e\u7684\u89c4\u6a21\u3002\u6bcf\u4e00\u4e24\u5e74\u4f1a\u6709\u4e00\u4e2a\u65b0\u7684\u4f18\u5316\u7b97\u6cd5\u51fa\u6765\uff0c\u4f46\u5b83\u4eec\u57fa\u672c\u90fd\u662f\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u53d8\u79cd\u3002\n\n## \u7ec3\u4e60\n\n\u5c1d\u8bd5\u589e\u5927\u5b66\u4e60\u7387\uff0c\u4f60\u4f1a\u9a6c\u4e0a\u53d1\u73b0\u7ed3\u679c\u53d8\u5f97\u5f88\u7cdf\u7cd5\uff0c\u7cbe\u5ea6\u57fa\u672c\u5f98\u5f8a\u5728\u968f\u673a\u76840.1\u5de6\u53f3\u3002\u8fd9\u662f\u4e3a\u4ec0\u4e48\u5462\uff1f\u63d0\u793a\uff1a\n\n- \u6253\u5370\u4e0boutput\u770b\u770b\u662f\u4e0d\u662f\u6709\u4ec0\u4e48\u5f02\u5e38\n- \u524d\u9762\u7ebf\u6027\u56de\u5f52\u8fd8\u597d\u597d\u7684\uff0c\u8fd9\u91cc\u6211\u4eec\u5728net()\u91cc\u52a0\u4e86\u4ec0\u4e48\u5462\uff1f\n- \u5982\u679c\u7ed9exp\u8f93\u5165\u4e2a\u5f88\u5927\u7684\u6570\u4f1a\u600e\u4e48\u6837\uff1f\n- \u5373\u4f7f\u89e3\u51b3exp\u7684\u95ee\u9898\uff0c\u6c42\u51fa\u6765\u7684\u5bfc\u6570\u662f\u4e0d\u662f\u8fd8\u662f\u4e0d\u7a33\u5b9a\uff1f\n\n\u8bf7\u4ed4\u7ec6\u60f3\u60f3\u518d\u53bb\u5bf9\u6bd4\u4e0b\u6211\u4eec\u5c0f\u4f19\u4f34\u4e4b\u4e00@[pluskid](https://github.com/pluskid)\u65e9\u5e74\u5199\u7684\u4e00\u7bc7[blog\u89e3\u91ca\u8fd9\u4e2a\u95ee\u9898](http://freemind.pluskid.org/machine-learning/softmax-vs-softmax-loss-numerical-stability/)\uff0c\u770b\u770b\u4f60\u60f3\u7684\u662f\u4e0d\u662f\u4e0d\u4e00\u6837\u3002\n\n**\u5410\u69fd\u548c\u8ba8\u8bba\u6b22\u8fce\u70b9**[\u8fd9\u91cc](https://discuss.gluon.ai/t/topic/741)", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 1.6 (Unsupported)", 
            "name": "python2", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}