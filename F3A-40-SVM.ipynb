{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Modern Data Science \n**(Module 03: Pattern Classification)**\n\n---\n- Materials in this module include resources collected from various open-source online repositories.\n- You are free to use, change and distribute this package.\n\nPrepared by and for \n**Student Members** |\n2006-2018 [TULIP Lab](http://www.tulip.org.au), Australia\n\n---\n\n\n# Session J - Support Vector Machines", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Import the needed python modules and the data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!pip install wget"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport wget\n%matplotlib inline"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wget.download('https://github.com/tuliplab/mds/raw/master/Jupyter/data/cervical.txt')\n\ndata = pd.read_table(\"cervical.txt\")\ndata.shape"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "data.head()"
        }, 
        {
            "source": "### Let's look at the library sizes (total read counts per sample)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sizes = data.sum(numeric_only=True)\nsizes.plot.bar()"
        }, 
        {
            "source": "### Normalization\n\nOur library sizes are very different.  Lets normalize the data for library size so we are comparing apples to apples.\n\nHere I use the normalization method of counts per milion (CPM).  We divide each count by the library size to give the proportion of total reads for each gene, then multiply by 1 million to get counts per 1 million.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ID = data.ID\ndata = data.drop('ID', 1)\nsums = data.sum()\ncpm = (data.div(sums))*1000000\ncpm.insert(loc=0, column='ID', value=ID)\ncpm.shape"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cpm.head()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sizes = cpm.sum(numeric_only=True)\nsizes.plot.bar()"
        }, 
        {
            "source": "### Here I re-format the data into a form suitable for input into the machine learning algorithm", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cpm = cpm.transpose()\ncpm = np.array(cpm[1:])\nclass_labels = np.array([\"normal\"]*29 + [\"tumor\"]*29)"
        }, 
        {
            "source": "### Train/Test Split - split the data into a training set and a testing set", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(cpm, class_labels, test_size=0.20, random_state=2)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print(X_train.shape)\nprint(X_test.shape)"
        }, 
        {
            "source": "### Now we'll use support vector machines with a linear kernel to create a classifier", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn import svm\nsvc = svm.SVC(kernel='linear', C=1.0).fit(X_train, y_train)"
        }, 
        {
            "source": "### Predict classifications of the test set data with our model and see how well the model performs", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Here are the predictions:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "predictions = svc.predict(X_test)\nprint(predictions)"
        }, 
        {
            "source": "Here is the ground truth (we know what the samples are ahead of time):", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print(y_test)"
        }, 
        {
            "source": "Here is our prediction accuracy:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print(\"Prediction accuracy = \", round((svc.score(X_test, y_test)*100), 1), \"%\")"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }, 
        "anaconda-cloud": {}
    }, 
    "nbformat": 4
}