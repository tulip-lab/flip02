{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Modern Data Science \n**(Module 03: Pattern Classification)**\n\n---\n- Materials in this module include resources collected from various open-source online repositories.\n- You are free to use, change and distribute this package.\n\nPrepared by and for \n**Student Members** |\n2006-2018 [TULIP Lab](http://www.tulip.org.au), Australia\n\n---\n\n\n# Session G - Optimization and Root Finding", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy as scipy\nfrom scipy.interpolate import interp1d"
        }, 
        {
            "source": "Many problems in statistics can be reduced to optimization problems, which in turn are reduced to root finding (because we optimize functions by taking derivatives and finding the zeroes of the derivative functions). Before we dive into the techniques, lets look at some examples of where optimization comes up in statistics.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def f(x):\n    return x**3 + 4*x**2 -3\n\nx = np.linspace(-3.1, 0, 100)\nplt.plot(x, x**3 + 4*x**2 -3)\n\na = -3.0\nb = -0.5\nc = 0.5*(a+b)\n\nplt.text(a,-1,\"a\")\nplt.text(b,-1,\"b\")\nplt.text(c,-1,\"c\")\n\nplt.scatter([a,b,c], [f(a), f(b),f(c)], s=50, facecolors='none')\nplt.scatter([a,b,c], [0,0,0], s=50, c='red')\n\nxaxis = plt.axhline(0);"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x = np.linspace(-3.1, 0, 100)\nplt.plot(x, x**3 + 4*x**2 -3)\n\nd = 0.5*(b+c)\n\nplt.text(d,-1,\"d\")\nplt.text(b,-1,\"b\")\nplt.text(c,-1,\"c\")\n\nplt.scatter([d,b,c], [f(d), f(b),f(c)], s=50, facecolors='none')\nplt.scatter([d,b,c], [0,0,0], s=50, c='red')\n\nxaxis = plt.axhline(0);"
        }, 
        {
            "source": "We can terminate the process whenever the function evaluated at the new midpoint is \u2018close enough\u2019 to zero. This method is an example of what are known as \u2018bracketed methods\u2019. This means the root is \u2018bracketed\u2019 by the end-points (it is somewhere in between). Another class of methods are \u2018open methods\u2019 - the root need not be somewhere in between the end-points (but it usually needs to be close!)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Secant Method", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The secant method also begins with two initial points, but without the constraint that the function values are of opposite signs. We use the secant line to extrapolate the next candidate point.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def f(x):\n    return (x**3-2*x+7)/(x**4+2)\n\nx = np.arange(-3,5, 0.1);\ny = f(x)\n\np1=plt.plot(x, y)\nplt.xlim(-3, 4)\nplt.ylim(-.5, 4)\nplt.xlabel('x')\nplt.axhline(0)\nt = np.arange(-10, 5., 0.1)\n\nx0=-1.2\nx1=-0.5\nxvals = []\nxvals.append(x0)\nxvals.append(x1)\nnotconverge = 1\ncount = 0\ncols=['r--','b--','g--','y--']\nwhile (notconverge==1 and count <  3):\n    slope=(f(xvals[count+1])-f(xvals[count]))/(xvals[count+1]-xvals[count])\n    intercept=-slope*xvals[count+1]+f(xvals[count+1])\n    plt.plot(t, slope*t + intercept, cols[count])\n    nextval = -intercept/slope\n    if abs(f(nextval)) < 0.001:\n        notconverge=0\n    else:\n        xvals.append(nextval)\n    count = count+1\n\nplt.show()"
        }, 
        {
            "source": "## Newton-Rhapson Method", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "We want to find the value $\u03b8$ so that some (differentiable) function $g(\u03b8)=0$. Idea: start with a guess, $\u03b8_0$. Let $\u03b8^~ $ denote the value of $\u03b8$ for which $g(\u03b8)=0$ and define $h=\u03b8^~\u2212\u03b8_0$. Then:\n$$ g(\u03b8^~) = 0$$\n$$ g(\u03b8^~) = g(\u03b8_0+h) $$", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Example:\nlet:\n$$ g(x) = x^3-2x+7{\\}\\x^4+2 $$\nThe graph of this function is:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x = np.arange(-5,5, 0.1);\ny = (x**3-2*x+7)/(x**4+2)\n\np1=plt.plot(x, y)\nplt.xlim(-4, 4)\nplt.ylim(-.5, 4)\nplt.xlabel('x')\nplt.axhline(0)\nplt.title('Example Function')\nplt.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x = np.arange(-5,5, 0.1);\ny = (x**3-2*x+7)/(x**4+2)\n\np1=plt.plot(x, y)\nplt.xlim(-4, 4)\nplt.ylim(-.5, 4)\nplt.xlabel('x')\nplt.axhline(0)\nplt.title('Good Guess')\nt = np.arange(-5, 5., 0.1)\n\nx0=-1.5\nxvals = []\nxvals.append(x0)\nnotconverge = 1\ncount = 0\ncols=['r--','b--','g--','y--','c--','m--','k--','w--']\nwhile (notconverge==1 and count <  6):\n    funval=(xvals[count]**3-2*xvals[count]+7)/(xvals[count]**4+2)\n    slope=-((4*xvals[count]**3 *(7 - 2 *xvals[count] + xvals[count]**3))/(2 + xvals[count]**4)**2) + (-2 + 3 *xvals[count]**2)/(2 + xvals[count]**4)\n\n    intercept=-slope*xvals[count]+(xvals[count]**3-2*xvals[count]+7)/(xvals[count]**4+2)\n\n    plt.plot(t, slope*t + intercept, cols[count])\n    nextval = -intercept/slope\n    if abs(funval) < 0.01:\n        notconverge=0\n    else:\n        xvals.append(nextval)\n    count = count+1\n\nplt.show()"
        }, 
        {
            "source": "From the graph, we see the zero is near -2. We make an initial guess of\n$$x=\u22121.5$$\n\nWe have made an excellent choice for our first guess, and we can see rapid convergence!", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "funval"
        }, 
        {
            "source": "In fact, the Newton-Rhapson method converges quadratically. However, NR (and the secant method) have a fatal flaw:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x = np.arange(-5,5, 0.1);\ny = (x**3-2*x+7)/(x**4+2)\n\np1=plt.plot(x, y)\nplt.xlim(-4, 4)\nplt.ylim(-.5, 4)\nplt.xlabel('x')\nplt.axhline(0)\nplt.title('Bad Guess')\nt = np.arange(-5, 5., 0.1)\n\nx0=-0.5\nxvals = []\nxvals.append(x0)\nnotconverge = 1\ncount = 0\ncols=['r--','b--','g--','y--','c--','m--','k--','w--']\nwhile (notconverge==1 and count <  6):\n    funval=(xvals[count]**3-2*xvals[count]+7)/(xvals[count]**4+2)\n    slope=-((4*xvals[count]**3 *(7 - 2 *xvals[count] + xvals[count]**3))/(2 + xvals[count]**4)**2) + (-2 + 3 *xvals[count]**2)/(2 + xvals[count]**4)\n\n    intercept=-slope*xvals[count]+(xvals[count]**3-2*xvals[count]+7)/(xvals[count]**4+2)\n\n    plt.plot(t, slope*t + intercept, cols[count])\n    nextval = -intercept/slope\n    if abs(funval) < 0.01:\n        notconverge = 0\n    else:\n        xvals.append(nextval)\n    count = count+1\n\nplt.show()"
        }, 
        {
            "source": "We have stumbled on the horizontal asymptote. The algorithm fails to converge.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Basins of Attraction Can Be \u2018Close\u2019", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def f(x):\n    return x**3 - 2*x**2 - 11*x +12\ndef s(x):\n    return 3*x**2 - 4*x - 11\n\nx = np.arange(-5,5, 0.1);\n\np1=plt.plot(x, f(x))\nplt.xlim(-4, 5)\nplt.ylim(-20, 22)\nplt.xlabel('x')\nplt.axhline(0)\nplt.title('Basin of Attraction')\nt = np.arange(-5, 5., 0.1)\n\nx0=2.43\nxvals = []\nxvals.append(x0)\nnotconverge = 1\ncount = 0\ncols=['r--','b--','g--','y--','c--','m--','k--','w--']\nwhile (notconverge==1 and count <  6):\n    funval = f(xvals[count])\n    slope = s(xvals[count])\n\n    intercept=-slope*xvals[count]+funval\n\n    plt.plot(t, slope*t + intercept, cols[count])\n    nextval = -intercept/slope\n    if abs(funval) < 0.01:\n        notconverge = 0\n    else:\n        xvals.append(nextval)\n    count = count+1\n\nplt.show()\nxvals[count-1]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "p1=plt.plot(x, f(x))\nplt.xlim(-4, 5)\nplt.ylim(-20, 22)\nplt.xlabel('x')\nplt.axhline(0)\nplt.title('Basin of Attraction')\nt = np.arange(-5, 5., 0.1)\n\nx0=2.349\nxvals = []\nxvals.append(x0)\nnotconverge = 1\ncount = 0\ncols=['r--','b--','g--','y--','c--','m--','k--','w--']\nwhile (notconverge==1 and count <  6):\n    funval = f(xvals[count])\n    slope = s(xvals[count])\n\n    intercept=-slope*xvals[count]+funval\n\n    plt.plot(t, slope*t + intercept, cols[count])\n    nextval = -intercept/slope\n    if abs(funval) < 0.01:\n        notconverge = 0\n    else:\n        xvals.append(nextval)\n    count = count+1\n\nplt.show()\nxvals[count-1]"
        }, 
        {
            "source": "#### Convergence Rate\nThe following is a derivation of the convergence rate of the NR method:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Inverse Quadratic Interpolation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Inverse quadratic interpolation is a type of polynomial interpolation. Polynomial interpolation simply means we find the polynomial of least degree that fits a set of points. In quadratic interpolation, we use three points, and find the quadratic polynomial that passes through those three points.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def f(x):\n    return (x - 2) * x * (x + 2)**2\n\n\nx = np.arange(-5,5, 0.1);\nplt.plot(x, f(x))\nplt.xlim(-3.5, 0.5)\nplt.ylim(-5, 16)\nplt.xlabel('x')\nplt.axhline(0)\nplt.title(\"Quadratic Interpolation\")\n\n#First Interpolation\nx0=np.array([-3,-2.5,-1.0])\ny0=f(x0)\nf2 = interp1d(x0, y0,kind='quadratic')\n\n#Plot parabola\nxs = np.linspace(-3, -1, num=10000, endpoint=True)\nplt.plot(xs, f2(xs))\n\n#Plot first triplet\nplt.plot(x0, f(x0),'ro');\nplt.scatter(x0, f(x0), s=50, c='yellow');\n\n#New x value\nxnew=xs[np.where(abs(f2(xs))==min(abs(f2(xs))))]\n\nplt.scatter(np.append(xnew,xnew), np.append(0,f(xnew)), c='black');\n\n#New triplet\nx1=np.append([-3,-2.5],xnew)\ny1=f(x1)\nf2 = interp1d(x1, y1,kind='quadratic')\n\n#New Parabola\nxs = np.linspace(min(x1), max(x1), num=100, endpoint=True)\nplt.plot(xs, f2(xs))\n\nxnew=xs[np.where(abs(f2(xs))==min(abs(f2(xs))))]\nplt.scatter(np.append(xnew,xnew), np.append(0,f(xnew)), c='green');"
        }, 
        {
            "source": "We aren\u2019t so much interested in deriving this as we are understanding the procedure:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x = np.arange(-5,5, 0.1);\nplt.plot(x, f(x))\nplt.xlim(-3.5, 0.5)\nplt.ylim(-5, 16)\nplt.xlabel('x')\nplt.axhline(0)\nplt.title(\"Inverse Quadratic Interpolation\")\n\n#First Interpolation\nx0=np.array([-3,-2.5,1])\ny0=f(x0)\nf2 = interp1d(y0, x0,kind='quadratic')\n\n#Plot parabola\nxs = np.linspace(min(f(x0)), max(f(x0)), num=10000, endpoint=True)\nplt.plot(f2(xs), xs)\n\n#Plot first triplet\nplt.plot(x0, f(x0),'ro');\nplt.scatter(x0, f(x0), s=50, c='yellow');"
        }, 
        {
            "source": "## Brent\u2019s Method\nBrent\u2019s method is a combination of bisection, secant and inverse quadratic interpolation. Like bisection, it is a \u2018bracketed\u2019 method (starts with points (a,b) such that $f(a)f(b)<0$\n\n\nRoughly speaking, the method begins by using the secant method to obtain a third point c\n, then uses inverse quadratic interpolation to generate the next possible root. Without going into too much detail, the algorithm attempts to assess when interpolation will go awry, and if so, performs a bisection step. Also, it has certain criteria to reject an iterate. If that happens, the next step will be linear interpolation (secant method).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### The Brent method is the default method that scypy uses to minimize a univariate function:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from scipy.optimize import minimize_scalar\n\ndef f(x):\n    return (x - 2) * x * (x + 2)**2\n\nres = minimize_scalar(f)\nres.x"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x = np.arange(-5,5, 0.1);\np1=plt.plot(x, f(x))\nplt.xlim(-4, 4)\nplt.ylim(-10, 20)\nplt.xlabel('x')\nplt.axhline(0)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# To find zeroes, use\nscipy.optimize.brentq(f,-1,.5)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "scipy.optimize.brentq(f,.5,3)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "scipy.optimize.newton(f,-3)"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }, 
        "anaconda-cloud": {}
    }, 
    "nbformat": 4
}