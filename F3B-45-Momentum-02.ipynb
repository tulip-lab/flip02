{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# \u52a8\u91cf\u6cd5 --- \u4f7f\u7528Gluon\n\n\n\u5728`Gluon`\u91cc\uff0c\u4f7f\u7528\u52a8\u91cf\u6cd5\u5f88\u5bb9\u6613\u3002\u6211\u4eec\u65e0\u9700\u91cd\u65b0\u5b9e\u73b0\u5b83\u3002\u4f8b\u5982\uff0c\u5728\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49`momentum`\u53c2\u6570\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "1"
                }
            }, 
            "outputs": [], 
            "source": "import mxnet as mx\nfrom mxnet import autograd\nfrom mxnet import gluon\nfrom mxnet import ndarray as nd\nimport numpy as np\nimport random\n\nmx.random.seed(1)\nrandom.seed(1)\n\n# \u751f\u6210\u6570\u636e\u96c6\u3002\nnum_inputs = 2\nnum_examples = 1000\ntrue_w = [2, -3.4]\ntrue_b = 4.2\nX = nd.random_normal(scale=1, shape=(num_examples, num_inputs))\ny = true_w[0] * X[:, 0] + true_w[1] * X[:, 1] + true_b\ny += .01 * nd.random_normal(scale=1, shape=y.shape)\ndataset = gluon.data.ArrayDataset(X, y)\n\nnet = gluon.nn.Sequential()\nnet.add(gluon.nn.Dense(1))\nsquare_loss = gluon.loss.L2Loss()"
        }, 
        {
            "source": "\u4e3a\u4e86\u4f7f\u5b66\u4e60\u7387\u5728\u4e24\u4e2aepoch\u540e\u81ea\u6211\u8870\u51cf\uff0c\u6211\u4eec\u9700\u8981\u8bbf\u95ee`gluon.Trainer`\u7684`learning_rate`\u5c5e\u6027\u548c`set_learning_rate`\u51fd\u6570\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "2"
                }
            }, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib as mpl\nmpl.rcParams['figure.dpi']= 120\nimport matplotlib.pyplot as plt\n\ndef train(batch_size, lr, mom, epochs, period):\n    assert period >= batch_size and period % batch_size == 0\n    net.collect_params().initialize(mx.init.Normal(sigma=1), force_reinit=True)\n    # \u52a8\u91cf\u6cd5\u3002\n    trainer = gluon.Trainer(net.collect_params(), 'sgd',\n                            {'learning_rate': lr, 'momentum': mom})\n    data_iter = gluon.data.DataLoader(dataset, batch_size, shuffle=True)\n    total_loss = [np.mean(square_loss(net(X), y).asnumpy())]\n    \n    for epoch in range(1, epochs + 1):\n        # \u91cd\u8bbe\u5b66\u4e60\u7387\u3002\n        if epoch > 2:\n            trainer.set_learning_rate(trainer.learning_rate * 0.1)\n        for batch_i, (data, label) in enumerate(data_iter):\n            with autograd.record():\n                output = net(data)\n                loss = square_loss(output, label)\n            loss.backward()\n            trainer.step(batch_size)\n\n            if batch_i * batch_size % period == 0:\n                total_loss.append(np.mean(square_loss(net(X), y).asnumpy()))\n        print(\"Batch size %d, Learning rate %f, Epoch %d, loss %.4e\" % \n              (batch_size, trainer.learning_rate, epoch, total_loss[-1]))\n\n    print('w:', np.reshape(net[0].weight.data().asnumpy(), (1, -1)), \n          'b:', net[0].bias.data().asnumpy()[0], '\\n')\n    x_axis = np.linspace(0, epochs, len(total_loss), endpoint=True)\n    plt.semilogy(x_axis, total_loss)\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.show()"
        }, 
        {
            "source": "\u4f7f\u7528\u52a8\u91cf\u6cd5\uff0c\u6700\u7ec8\u5b66\u5230\u7684\u53c2\u6570\u503c\u4e0e\u771f\u5b9e\u503c\u8f83\u63a5\u8fd1\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "3"
                }
            }, 
            "outputs": [], 
            "source": "train(batch_size=10, lr=0.2, mom=0.9, epochs=3, period=10)"
        }, 
        {
            "source": "## \u7ed3\u8bba\n\n* \u4f7f\u7528`Gluon`\u7684`Trainer`\u53ef\u4ee5\u8f7b\u677e\u4f7f\u7528\u52a8\u91cf\u6cd5\u3002\n\n## \u7ec3\u4e60\n\n* \u5982\u679c\u60f3\u7528\u4ee5\u4e0a\u4ee3\u7801\u91cd\u73b0\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff0c\u5e94\u8be5\u628a\u52a8\u91cf\u53c2\u6570\u6539\u4e3a\u591a\u5c11\uff1f\n\n**\u5410\u69fd\u548c\u8ba8\u8bba\u6b22\u8fce\u70b9**[\u8fd9\u91cc](https://discuss.gluon.ai/t/topic/1880)", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {}, 
    "nbformat": 4
}