{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# Adam --- \u4ece0\u5f00\u59cb\n\nAdam\u662f\u4e00\u4e2a\u7ec4\u5408\u4e86[\u52a8\u91cf\u6cd5](momentum-scratch.md)\u548c[RMSProp](rmsprop-scratch.md)\u7684\u4f18\u5316\u7b97\u6cd5\u3002\n\n\n\n## Adam\u7b97\u6cd5\n\nAdam\u7b97\u6cd5\u4f1a\u4f7f\u7528\u4e00\u4e2a\u52a8\u91cf\u53d8\u91cf$\\mathbf{v}$\u548c\u4e00\u4e2aRMSProp\u4e2d\u68af\u5ea6\u6309\u5143\u7d20\u5e73\u65b9\u7684\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u53d8\u91cf$\\mathbf{s}$\uff0c\u5e76\u5c06\u5b83\u4eec\u4e2d\u6bcf\u4e2a\u5143\u7d20\u521d\u59cb\u5316\u4e3a0\u3002\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0c\u9996\u5148\u8ba1\u7b97[\u5c0f\u6279\u91cf\u68af\u5ea6](gd-sgd-scratch.md) $\\mathbf{g}$\uff0c\u5e76\u9012\u589e\u8fed\u4ee3\u6b21\u6570\n\n$$t := t + 1$$\n\n\u7136\u540e\u5bf9\u68af\u5ea6\u505a\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u5e76\u8ba1\u7b97\u52a8\u91cf\u53d8\u91cf$\\mathbf{v}$:\n\n$$\\mathbf{v} := \\beta_1 \\mathbf{v} + (1 - \\beta_1) \\mathbf{g} $$\n\n\n\u8be5\u68af\u5ea6\u6309\u5143\u7d20\u5e73\u65b9\u540e\u505a\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u5e76\u8ba1\u7b97$\\mathbf{s}$\uff1a\n\n$$\\mathbf{s} := \\beta_2 \\mathbf{s} + (1 - \\beta_2) \\mathbf{g} \\odot \\mathbf{g} $$\n\n\n\u5728Adam\u7b97\u6cd5\u91cc\uff0c\u4e3a\u4e86\u51cf\u8f7b$\\mathbf{v}$\u548c$\\mathbf{s}$\u88ab\u521d\u59cb\u5316\u4e3a0\u5728\u8fed\u4ee3\u521d\u671f\u5bf9\u8ba1\u7b97\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u7684\u5f71\u54cd\uff0c\u6211\u4eec\u505a\u4e0b\u9762\u7684\u504f\u5dee\u4fee\u6b63\uff1a\n\n$$\\hat{\\mathbf{v}} := \\frac{\\mathbf{v}}{1 - \\beta_1^t} $$\n\n\u548c\n\n$$\\hat{\\mathbf{s}} := \\frac{\\mathbf{s}}{1 - \\beta_2^t} $$\n\n\n\n\u53ef\u4ee5\u770b\u5230\uff0c\u5f53$0 \\leq \\beta_1, \\beta_2 < 1$\u65f6\uff08\u7b97\u6cd5\u4f5c\u8005\u5efa\u8bae\u5206\u522b\u8bbe\u4e3a0.9\u548c0.999\uff09\uff0c\u5f53\u8fed\u4ee3\u540e\u671f$t$\u8f83\u5927\u65f6\uff0c\u504f\u5dee\u4fee\u6b63\u51e0\u4e4e\u5c31\u4e0d\u518d\u6709\u5f71\u54cd\u3002\u6211\u4eec\u4f7f\u7528\u4ee5\u4e0a\u504f\u5dee\u4fee\u6b63\u540e\u7684\u52a8\u91cf\u53d8\u91cf\u548cRMSProp\u4e2d\u68af\u5ea6\u6309\u5143\u7d20\u5e73\u65b9\u7684\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u53d8\u91cf\uff0c\u5c06\u6a21\u578b\u53c2\u6570\u4e2d\u6bcf\u4e2a\u5143\u7d20\u7684\u5b66\u4e60\u7387\u901a\u8fc7\u6309\u5143\u7d20\u64cd\u4f5c\u91cd\u65b0\u8c03\u6574\u4e00\u4e0b\uff1a\n\n$$\\mathbf{g}^\\prime := \\frac{\\eta \\hat{\\mathbf{v}}}{\\sqrt{\\hat{\\mathbf{s}} + \\epsilon}} $$\n\n\u5176\u4e2d$\\eta$\u662f\u521d\u59cb\u5b66\u4e60\u7387\uff0c$\\epsilon$\u662f\u4e3a\u4e86\u7ef4\u6301\u6570\u503c\u7a33\u5b9a\u6027\u800c\u6dfb\u52a0\u7684\u5e38\u6570\uff0c\u4f8b\u5982$10^{-8}$\u3002\u548cAdagrad\u4e00\u6837\uff0c\u6a21\u578b\u53c2\u6570\u4e2d\u6bcf\u4e2a\u5143\u7d20\u90fd\u5206\u522b\u62e5\u6709\u81ea\u5df1\u7684\u5b66\u4e60\u7387\u3002\n\n\u540c\u6837\u5730\uff0c\u6700\u540e\u7684\u53c2\u6570\u8fed\u4ee3\u6b65\u9aa4\u4e0e\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7c7b\u4f3c\u3002\u53ea\u662f\u8fd9\u91cc\u68af\u5ea6\u524d\u7684\u5b66\u4e60\u7387\u5df2\u7ecf\u88ab\u8c03\u6574\u8fc7\u4e86\uff1a\n\n$$\\mathbf{x} := \\mathbf{x} - \\mathbf{g}^\\prime $$\n\n\n## Adam\u7684\u5b9e\u73b0\n\n\nAdam\u7684\u5b9e\u73b0\u5f88\u7b80\u5355\u3002\u6211\u4eec\u53ea\u9700\u8981\u628a\u4e0a\u9762\u7684\u6570\u5b66\u516c\u5f0f\u7ffb\u8bd1\u6210\u4ee3\u7801\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Adam\u3002\ndef adam(params, vs, sqrs, lr, batch_size, t):\n    beta1 = 0.9\n    beta2 = 0.999\n    eps_stable = 1e-8\n    for param, v, sqr in zip(params, vs, sqrs):      \n        g = param.grad / batch_size\n        v[:] = beta1 * v + (1. - beta1) * g\n        sqr[:] = beta2 * sqr + (1. - beta2) * nd.square(g)\n        v_bias_corr = v / (1. - beta1 ** t)\n        sqr_bias_corr = sqr / (1. - beta2 ** t)\n        div = lr * v_bias_corr / (nd.sqrt(sqr_bias_corr) + eps_stable)        \n        param[:] = param - div"
        }, 
        {
            "source": "## \u5b9e\u9a8c\n\n\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u4ee5\u7ebf\u6027\u56de\u5f52\u4e3a\u4f8b\u3002\u5176\u4e2d\u771f\u5b9e\u53c2\u6570`w`\u4e3a[2, -3.4]\uff0c`b`\u4e3a4.2\u3002\u6211\u4eec\u628a\u7b97\u6cd5\u4e2d\u57fa\u4e8e\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u7684\u53d8\u91cf\u521d\u59cb\u5316\u4e3a\u548c\u53c2\u6570\u5f62\u72b6\u76f8\u540c\u7684\u96f6\u5f20\u91cf\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "1"
                }
            }, 
            "outputs": [], 
            "source": "import mxnet as mx\nfrom mxnet import autograd\nfrom mxnet import ndarray as nd\nfrom mxnet import gluon\nimport random\n\nmx.random.seed(1)\nrandom.seed(1)\n\n# \u751f\u6210\u6570\u636e\u96c6\u3002\nnum_inputs = 2\nnum_examples = 1000\ntrue_w = [2, -3.4]\ntrue_b = 4.2\nX = nd.random_normal(scale=1, shape=(num_examples, num_inputs))\ny = true_w[0] * X[:, 0] + true_w[1] * X[:, 1] + true_b\ny += .01 * nd.random_normal(scale=1, shape=y.shape)\ndataset = gluon.data.ArrayDataset(X, y)\n\n# \u6784\u9020\u8fed\u4ee3\u5668\u3002\nimport random\ndef data_iter(batch_size):\n    idx = list(range(num_examples))\n    random.shuffle(idx)\n    for batch_i, i in enumerate(range(0, num_examples, batch_size)):\n        j = nd.array(idx[i: min(i + batch_size, num_examples)])\n        yield batch_i, X.take(j), y.take(j)\n\n# \u521d\u59cb\u5316\u6a21\u578b\u53c2\u6570\u3002\ndef init_params():\n    w = nd.random_normal(scale=1, shape=(num_inputs, 1))\n    b = nd.zeros(shape=(1,))\n    params = [w, b]\n    vs = []\n    sqrs = []\n    for param in params:\n        param.attach_grad()\n        # \u628a\u7b97\u6cd5\u4e2d\u57fa\u4e8e\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u7684\u53d8\u91cf\u521d\u59cb\u5316\u4e3a\u548c\u53c2\u6570\u5f62\u72b6\u76f8\u540c\u7684\u96f6\u5f20\u91cf\u3002\n        vs.append(param.zeros_like())\n        sqrs.append(param.zeros_like())\n    return params, vs, sqrs\n\n# \u7ebf\u6027\u56de\u5f52\u6a21\u578b\u3002\ndef net(X, w, b):\n    return nd.dot(X, w) + b\n\n# \u635f\u5931\u51fd\u6570\u3002\ndef square_loss(yhat, y):\n    return (yhat - y.reshape(yhat.shape)) ** 2 / 2"
        }, 
        {
            "source": "\u63a5\u4e0b\u6765\u5b9a\u4e49\u8bad\u7ec3\u51fd\u6570\u3002\u5f53epoch\u5927\u4e8e2\u65f6\uff08epoch\u4ece1\u5f00\u59cb\u8ba1\u6570\uff09\uff0c\u5b66\u4e60\u7387\u4ee5\u81ea\u4e580.1\u7684\u65b9\u5f0f\u81ea\u6211\u8870\u51cf\u3002\u8bad\u7ec3\u51fd\u6570\u7684period\u53c2\u6570\u8bf4\u660e\uff0c\u6bcf\u6b21\u91c7\u6837\u8fc7\u8be5\u6570\u76ee\u7684\u6570\u636e\u70b9\u540e\uff0c\u8bb0\u5f55\u5f53\u524d\u76ee\u6807\u51fd\u6570\u503c\u7528\u4e8e\u4f5c\u56fe\u3002\u4f8b\u5982\uff0c\u5f53period\u548cbatch_size\u90fd\u4e3a10\u65f6\uff0c\u6bcf\u6b21\u8fed\u4ee3\u540e\u5747\u4f1a\u8bb0\u5f55\u76ee\u6807\u51fd\u6570\u503c\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "2"
                }
            }, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib as mpl\nmpl.rcParams['figure.dpi']= 120\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef train(batch_size, lr, epochs, period):\n    assert period >= batch_size and period % batch_size == 0\n    [w, b], vs, sqrs = init_params()\n    total_loss = [np.mean(square_loss(net(X, w, b), y).asnumpy())]\n\n    # \u6ce8\u610fepoch\u4ece1\u5f00\u59cb\u8ba1\u6570\u3002\n    t = 0\n    for epoch in range(1, epochs + 1):\n        for batch_i, data, label in data_iter(batch_size):\n            with autograd.record():\n                output = net(data, w, b)\n                loss = square_loss(output, label)\n            loss.backward()\n            # \u5fc5\u987b\u5728\u8c03\u7528Adam\u524d\u3002\n            t += 1\n            adam([w, b], vs, sqrs, lr, batch_size, t)\n            if batch_i * batch_size % period == 0:\n                total_loss.append(np.mean(square_loss(net(X, w, b), y).asnumpy()))\n        print(\"Batch size %d, Learning rate %f, Epoch %d, loss %.4e\" % \n              (batch_size, lr, epoch, total_loss[-1]))\n    print('w:', np.reshape(w.asnumpy(), (1, -1)), \n          'b:', b.asnumpy()[0], '\\n')\n    x_axis = np.linspace(0, epochs, len(total_loss), endpoint=True)\n    plt.semilogy(x_axis, total_loss)\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.show()"
        }, 
        {
            "source": "\u4f7f\u7528Adam\uff0c\u6700\u7ec8\u5b66\u5230\u7684\u53c2\u6570\u503c\u4e0e\u771f\u5b9e\u503c\u8f83\u63a5\u8fd1\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "3"
                }
            }, 
            "outputs": [], 
            "source": "train(batch_size=10, lr=0.1, epochs=3, period=10)"
        }, 
        {
            "source": "## \u7ed3\u8bba\n\n* Adam\u7ec4\u5408\u4e86\u52a8\u91cf\u6cd5\u548cRMSProp\u3002\n\n\n## \u7ec3\u4e60\n\n* \u4f60\u662f\u600e\u6837\u7406\u89e3Adam\u7b97\u6cd5\u4e2d\u7684\u504f\u5dee\u4fee\u6b63\u9879\u7684\uff1f\n\n**\u5410\u69fd\u548c\u8ba8\u8bba\u6b22\u8fce\u70b9**[\u8fd9\u91cc](https://discuss.gluon.ai/t/topic/2279)", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {}, 
    "nbformat": 4
}