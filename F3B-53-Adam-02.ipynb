{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# Adam --- \u4f7f\u7528Gluon\n\n\n\u5728`Gluon`\u91cc\uff0c\u4f7f\u7528Adam\u5f88\u5bb9\u6613\u3002\u6211\u4eec\u65e0\u9700\u91cd\u65b0\u5b9e\u73b0\u5b83\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "1"
                }
            }, 
            "outputs": [], 
            "source": "import mxnet as mx\nfrom mxnet import autograd\nfrom mxnet import gluon\nfrom mxnet import ndarray as nd\nimport numpy as np\nimport random\n\nmx.random.seed(1)\nrandom.seed(1)\n\n# \u751f\u6210\u6570\u636e\u96c6\u3002\nnum_inputs = 2\nnum_examples = 1000\ntrue_w = [2, -3.4]\ntrue_b = 4.2\nX = nd.random_normal(scale=1, shape=(num_examples, num_inputs))\ny = true_w[0] * X[:, 0] + true_w[1] * X[:, 1] + true_b\ny += .01 * nd.random_normal(scale=1, shape=y.shape)\ndataset = gluon.data.ArrayDataset(X, y)\n\nnet = gluon.nn.Sequential()\nnet.add(gluon.nn.Dense(1))\nsquare_loss = gluon.loss.L2Loss()"
        }, 
        {
            "source": "\u6211\u4eec\u9700\u8981\u5728`gluon.Trainer`\u4e2d\u6307\u5b9a\u4f18\u5316\u7b97\u6cd5\u540d\u79f0`adam`\u5e76\u8bbe\u7f6e\u5b66\u4e60\u7387\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "2"
                }
            }, 
            "outputs": [], 
            "source": "%matplotlib inline\nimport matplotlib as mpl\nmpl.rcParams['figure.dpi']= 120\nimport matplotlib.pyplot as plt\n\ndef train(batch_size, lr, epochs, period):\n    assert period >= batch_size and period % batch_size == 0\n    net.collect_params().initialize(mx.init.Normal(sigma=1), force_reinit=True)\n    # Adam\u3002\n    trainer = gluon.Trainer(net.collect_params(), 'adam',\n                            {'learning_rate': lr})\n    data_iter = gluon.data.DataLoader(dataset, batch_size, shuffle=True)\n    total_loss = [np.mean(square_loss(net(X), y).asnumpy())]\n\n    for epoch in range(1, epochs + 1):\n        for batch_i, (data, label) in enumerate(data_iter):\n            with autograd.record():\n                output = net(data)\n                loss = square_loss(output, label)\n            loss.backward()\n            trainer.step(batch_size)\n            if batch_i * batch_size % period == 0:\n                total_loss.append(np.mean(square_loss(net(X), y).asnumpy()))\n        print(\"Batch size %d, Learning rate %f, Epoch %d, loss %.4e\" %\n              (batch_size, trainer.learning_rate, epoch, total_loss[-1]))\n\n    print('w:', np.reshape(net[0].weight.data().asnumpy(), (1, -1)),\n          'b:', net[0].bias.data().asnumpy()[0], '\\n')\n    x_axis = np.linspace(0, epochs, len(total_loss), endpoint=True)\n    plt.semilogy(x_axis, total_loss)\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.show()"
        }, 
        {
            "source": "\u4f7f\u7528Adam\uff0c\u6700\u7ec8\u5b66\u5230\u7684\u53c2\u6570\u503c\u4e0e\u771f\u5b9e\u503c\u8f83\u63a5\u8fd1\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "3"
                }
            }, 
            "outputs": [], 
            "source": "train(batch_size=10, lr=0.1, epochs=3, period=10)"
        }, 
        {
            "source": "## \u7ed3\u8bba\n\n* \u4f7f\u7528`Gluon`\u7684`Trainer`\u53ef\u4ee5\u8f7b\u677e\u4f7f\u7528Adam\u3002\n\n\n\n## \u7ec3\u4e60\n\n* \u8bd5\u7740\u4f7f\u7528\u5176\u4ed6Adam\u521d\u59cb\u5b66\u4e60\u7387\uff0c\u89c2\u5bdf\u5b9e\u9a8c\u7ed3\u679c\u3002\n\n\n\n## \u8d60\u8bd7\u4e00\u9996\u4ee5\u603b\u7ed3\u4f18\u5316\u7ae0\u8282\n\n\n> \u68af\u5ea6\u4e0b\u964d\u53ef\u6c89\u7538\uff0c  \u968f\u673a\u964d\u4f4e\u65b9\u5dee\u96be\u3002\n\n> \u5f15\u5165\u52a8\u91cf\u522b\u5f2f\u6162\uff0c  Adagrad\u68af\u65b9\u8d2a\u3002\n\n> Adadelta\u5b66\u7387\u6362\uff0c RMSProp\u68af\u65b9\u6743\u3002\n\n> Adam\u52a8\u91cfRMS\u4f34\uff0c  \u4f18\u5316\u8fd8\u9700\u5df1\u8c03\u53c2\u3002\n\n\n\u6ce8\u91ca\uff1a\n\n* \u68af\u65b9\uff1a\u68af\u5ea6\u6309\u5143\u7d20\u5e73\u65b9\n* \u8d2a\uff1a\u56e0\u8d2a\u5a6a\u6545\u800c\u4e0d\u65ad\u7d2f\u52a0\n* \u5b66\u7387\uff1a\u5b66\u4e60\u7387\n* \u6362\uff1a\u8fd9\u4e2a\u53c2\u6570\u88ab\u6362\u6210\u522b\u7684\u4e86\n* \u6743\uff1a\u6307\u6570\u52a0\u6743\u79fb\u52a8\u5e73\u5747\n\n**\u5410\u69fd\u548c\u8ba8\u8bba\u6b22\u8fce\u70b9**[\u8fd9\u91cc](https://discuss.gluon.ai/t/topic/2280)", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 1.6 (Unsupported)", 
            "name": "python2", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}