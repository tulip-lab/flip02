{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# \u5faa\u73af\u795e\u7ecf\u7f51\u7edc --- \u4f7f\u7528Gluon\n\n\u672c\u8282\u4ecb\u7ecd\u5982\u4f55\u4f7f\u7528`Gluon`\u8bad\u7ec3\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u3002\n\n\n## Penn Tree Bank (PTB) \u6570\u636e\u96c6\n\n\u6211\u4eec\u4ee5\u5355\u8bcd\u4e3a\u57fa\u672c\u5143\u7d20\u6765\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3002[Penn Tree Bank](https://catalog.ldc.upenn.edu/ldc99t42)\uff08PTB\uff09\u662f\u4e00\u4e2a\u6807\u51c6\u7684\u6587\u672c\u5e8f\u5217\u6570\u636e\u96c6\u3002\u5b83\u5305\u62ec\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002\n\n\u4e0b\u9762\u6211\u4eec\u8f7d\u5165\u6570\u636e\u96c6\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!wget https://github.com/mli/gluon-tutorials-zh/raw/master/data/ptb.zip"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ls"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "1"
                }
            }, 
            "outputs": [], 
            "source": "import math\nimport os\nimport time\nimport numpy as np\nimport mxnet as mx\nfrom mxnet import gluon, autograd\nfrom mxnet.gluon import nn, rnn\n\nimport zipfile\nwith zipfile.ZipFile('ptb.zip', 'r') as zin:\n    zin.extractall('data/')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ls -l data/ptb"
        }, 
        {
            "source": "## \u5efa\u7acb\u8bcd\u8bed\u7d22\u5f15\n\n\u4e0b\u9762\u5b9a\u4e49\u4e86`Dictionary`\u7c7b\u6765\u6620\u5c04\u8bcd\u8bed\u548c\u7d22\u5f15\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "2"
                }
            }, 
            "outputs": [], 
            "source": "class Dictionary(object):\n    def __init__(self):\n        self.word_to_idx = {}\n        self.idx_to_word = []\n\n    def add_word(self, word):\n        if word not in self.word_to_idx:\n            self.idx_to_word.append(word)\n            self.word_to_idx[word] = len(self.idx_to_word) - 1\n        return self.word_to_idx[word]\n\n    def __len__(self):\n        return len(self.idx_to_word)"
        }, 
        {
            "source": "\u4ee5\u4e0b\u7684`Corpus`\u7c7b\u6309\u7167\u8bfb\u53d6\u7684\u6587\u672c\u6570\u636e\u96c6\u5efa\u7acb\u6620\u5c04\u8bcd\u8bed\u548c\u7d22\u5f15\u7684\u8bcd\u5178\uff0c\u5e76\u5c06\u6587\u672c\u8f6c\u6362\u6210\u8bcd\u8bed\u7d22\u5f15\u7684\u5e8f\u5217\u3002\u8fd9\u6837\uff0c\u6bcf\u4e2a\u6587\u672c\u6570\u636e\u96c6\u5c31\u53d8\u6210\u4e86`NDArray`\u683c\u5f0f\u7684\u6574\u6570\u5e8f\u5217\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "3"
                }
            }, 
            "outputs": [], 
            "source": "class Corpus(object):\n    def __init__(self, path):\n        self.dictionary = Dictionary()\n        self.train = self.tokenize(path + 'train.txt')\n        self.valid = self.tokenize(path + 'valid.txt')\n        self.test = self.tokenize(path + 'test.txt')\n\n    def tokenize(self, path):\n        assert os.path.exists(path)\n        # \u5c06\u8bcd\u8bed\u6dfb\u52a0\u81f3\u8bcd\u5178\u3002\n        with open(path, 'r') as f:\n            tokens = 0\n            for line in f:\n                words = line.split() + ['<eos>']\n                tokens += len(words)\n                for word in words:\n                    self.dictionary.add_word(word)\n        # \u5c06\u6587\u672c\u8f6c\u6362\u6210\u8bcd\u8bed\u7d22\u5f15\u7684\u5e8f\u5217\uff08NDArray\u683c\u5f0f\uff09\u3002\n        with open(path, 'r') as f:\n            indices = np.zeros((tokens,), dtype='int32')\n            idx = 0\n            for line in f:\n                words = line.split() + ['<eos>']\n                for word in words:\n                    indices[idx] = self.dictionary.word_to_idx[word]\n                    idx += 1\n        return mx.nd.array(indices, dtype='int32')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ls -l data/ptb"
        }, 
        {
            "source": "\u770b\u4e00\u4e0b\u8bcd\u5178\u7684\u5927\u5c0f\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "4"
                }
            }, 
            "outputs": [], 
            "source": "data = 'data/ptb/ptb.'\ncorpus = Corpus(data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "4"
                }
            }, 
            "outputs": [], 
            "source": "vocab_size = len(corpus.dictionary)\nvocab_size"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "display(corpus.test)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "display(corpus.train)"
        }, 
        {
            "source": "## \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5e93\n\n\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\u4e00\u4e2a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5e93\u3002\u8fd9\u6837\u5c31\u53ef\u4ee5\u652f\u6301\u5404\u79cd\u4e0d\u540c\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e86\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "5"
                }
            }, 
            "outputs": [], 
            "source": "class RNNModel(gluon.Block):\n    \"\"\"\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5e93\"\"\"\n    def __init__(self, mode, vocab_size, embed_dim, hidden_dim,\n                 num_layers, dropout=0.5, **kwargs):\n        super(RNNModel, self).__init__(**kwargs)\n        with self.name_scope():\n            self.drop = nn.Dropout(dropout)\n            self.encoder = nn.Embedding(vocab_size, embed_dim,\n                                        weight_initializer=mx.init.Uniform(0.1))\n            if mode == 'rnn_relu':\n                self.rnn = rnn.RNN(hidden_dim, num_layers, activation='relu',\n                                   dropout=dropout, input_size=embed_dim)\n            elif mode == 'rnn_tanh':\n                self.rnn = rnn.RNN(hidden_dim, num_layers, dropout=dropout,\n                                   input_size=embed_dim)\n            elif mode == 'lstm':\n                self.rnn = rnn.LSTM(hidden_dim, num_layers, dropout=dropout,\n                                    input_size=embed_dim)\n            elif mode == 'gru':\n                self.rnn = rnn.GRU(hidden_dim, num_layers, dropout=dropout,\n                                   input_size=embed_dim)\n            else:\n                raise ValueError(\"Invalid mode %s. Options are rnn_relu, \"\n                                 \"rnn_tanh, lstm, and gru\"%mode)\n\n            self.decoder = nn.Dense(vocab_size, in_units=hidden_dim)\n            self.hidden_dim = hidden_dim\n\n    def forward(self, inputs, state):\n        emb = self.drop(self.encoder(inputs))\n        output, state = self.rnn(emb, state)\n        output = self.drop(output)\n        decoded = self.decoder(output.reshape((-1, self.hidden_dim)))\n        return decoded, state\n\n    def begin_state(self, *args, **kwargs):\n        return self.rnn.begin_state(*args, **kwargs)"
        }, 
        {
            "source": "## \u5b9a\u4e49\u53c2\u6570\n\n\u6211\u4eec\u63a5\u7740\u5b9a\u4e49\u6a21\u578b\u53c2\u6570\u3002\u6211\u4eec\u9009\u62e9\u4f7f\u7528ReLU\u4e3a\u6fc0\u6d3b\u51fd\u6570\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e3a\u4f8b\u3002\u8fd9\u91cc\u6211\u4eec\u628a`epochs`\u8bbe\u4e3a1\u662f\u4e3a\u4e86\u6f14\u793a\u65b9\u4fbf\u3002\n\n\n## \u591a\u5c42\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\n\n\u6211\u4eec\u901a\u8fc7`num_layers`\u8bbe\u7f6e\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u9690\u542b\u5c42\u7684\u5c42\u6570\uff0c\u4f8b\u59822\u3002\n\n\u5bf9\u4e8e\u4e00\u4e2a\u591a\u5c42\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u5f53\u524d\u65f6\u523b\u9690\u542b\u5c42\u7684\u8f93\u5165\u6765\u81ea\u540c\u4e00\u65f6\u523b\u8f93\u5165\u5c42\uff08\u5982\u679c\u6709\uff09\u6216\u4e0a\u4e00\u9690\u542b\u5c42\u7684\u8f93\u51fa\u3002\u6bcf\u4e00\u5c42\u7684\u9690\u542b\u72b6\u6001\u53ea\u6cbf\u7740\u540c\u4e00\u5c42\u4f20\u9012\u3002\n\n\u628a[\u5355\u5c42\u5faa\u73af\u795e\u7ecf\u7f51\u7edc](rnn-scratch.md)\u4e2d\u9690\u542b\u5c42\u7684\u6bcf\u4e2a\u5355\u5143\u5f53\u505a\u4e00\u4e2a\u51fd\u6570$f$\uff0c\u8fd9\u4e2a\u51fd\u6570\u5728$t$\u65f6\u523b\u7684\u8f93\u5165\u662f$\\mathbf{X}_t, \\mathbf{H}_{t-1}$\uff0c\u8f93\u51fa\u662f$\\mathbf{H}_t$\uff1a\n\n$$f(\\mathbf{X}_t, \\mathbf{H}_{t-1}) = \\mathbf{H}_t$$\n\n\u5047\u8bbe\u8f93\u5165\u4e3a\u7b2c0\u5c42\uff0c\u8f93\u51fa\u4e3a\u7b2c$L+1$\u5c42\uff0c\u5728\u4e00\u5171$L$\u4e2a\u9690\u542b\u5c42\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u4e0a\u5f0f\u4e2d\u53ef\u4ee5\u62d3\u5c55\u6210\u4ee5\u4e0b\u7684\u51fd\u6570:\n\n$$f(\\mathbf{H}_t^{(l-1)}, \\mathbf{H}_{t-1}^{(l)}) = \\mathbf{H}_t^{(l)}$$\n\n\u5982\u4e0b\u56fe\u6240\u793a\u3002\n\n![](https://github.com/mli/gluon-tutorials-zh/raw/master/img/multi-layer-rnn.svg)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "6"
                }
            }, 
            "outputs": [], 
            "source": "model_name = 'rnn_relu'\n\nembed_dim = 100\nhidden_dim = 100\nnum_layers = 2\nlr = 1.0\nclipping_norm = 0.2\nepochs = 1\nbatch_size = 32\nnum_steps = 5\ndropout_rate = 0.2\neval_period = 500"
        }, 
        {
            "source": "## \u6279\u91cf\u91c7\u6837\n\n\u6211\u4eec\u5c06\u6570\u636e\u8fdb\u4e00\u6b65\u5904\u7406\u4e3a\u4fbf\u4e8e\u76f8\u90bb\u6279\u91cf\u91c7\u6837\u7684\u683c\u5f0f\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "7"
                }
            }, 
            "outputs": [], 
            "source": "# \u5c1d\u8bd5\u4f7f\u7528GPU\nimport sys\nsys.path.append('..')\nimport utils\ncontext = utils.try_gpu()\n\ndef batchify(data, batch_size):\n    \"\"\"\u6570\u636e\u5f62\u72b6 (num_batches, batch_size)\"\"\"\n    num_batches = data.shape[0] // batch_size\n    data = data[:num_batches * batch_size]\n    data = data.reshape((batch_size, num_batches)).T\n    return data\n\ntrain_data = batchify(corpus.train, batch_size).as_in_context(context)\nval_data = batchify(corpus.valid, batch_size).as_in_context(context)\ntest_data = batchify(corpus.test, batch_size).as_in_context(context)\n\nmodel = RNNModel(model_name, vocab_size, embed_dim, hidden_dim,\n                       num_layers, dropout_rate)\nmodel.collect_params().initialize(mx.init.Xavier(), ctx=context)\ntrainer = gluon.Trainer(model.collect_params(), 'sgd',\n                        {'learning_rate': lr, 'momentum': 0, 'wd': 0})\nloss = gluon.loss.SoftmaxCrossEntropyLoss()\n\ndef get_batch(source, i):\n    seq_len = min(num_steps, source.shape[0] - 1 - i)\n    data = source[i : i + seq_len]\n    target = source[i + 1 : i + 1 + seq_len]\n    return data, target.reshape((-1,))"
        }, 
        {
            "source": "## \u4ece\u8ba1\u7b97\u56fe\u5206\u79bb\u9690\u542b\u72b6\u6001\n\n\u5728\u6a21\u578b\u8bad\u7ec3\u7684\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0c\u5f53\u524d\u6279\u91cf\u5e8f\u5217\u7684\u521d\u59cb\u9690\u542b\u72b6\u6001\u6765\u81ea\u4e0a\u4e00\u4e2a\u76f8\u90bb\u6279\u91cf\u5e8f\u5217\u7684\u8f93\u51fa\u9690\u542b\u72b6\u6001\u3002\u4e3a\u4e86\u4f7f\u6a21\u578b\u53c2\u6570\u7684\u68af\u5ea6\u8ba1\u7b97\u53ea\u4f9d\u8d56\u5f53\u524d\u7684\u6279\u91cf\u5e8f\u5217\uff0c\u4ece\u800c\u51cf\u5c0f\u6bcf\u6b21\u8fed\u4ee3\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528`detach`\u51fd\u6570\u6765\u5c06\u9690\u542b\u72b6\u6001\u4ece\u8ba1\u7b97\u56fe\u5206\u79bb\u51fa\u6765\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "8"
                }
            }, 
            "outputs": [], 
            "source": "def detach(state):\n    if isinstance(state, (tuple, list)):\n        state = [i.detach() for i in state]\n    else:\n        state = state.detach()\n    return state"
        }, 
        {
            "source": "## \u8bad\u7ec3\u548c\u8bc4\u4ef7\u6a21\u578b\n\n\u548c\u4e4b\u524d\u4e00\u6837\uff0c\u6211\u4eec\u5b9a\u4e49\u6a21\u578b\u8bc4\u4ef7\u51fd\u6570\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "9"
                }
            }, 
            "outputs": [], 
            "source": "def model_eval(data_source):\n    total_L = 0.0\n    ntotal = 0\n    hidden = model.begin_state(func = mx.nd.zeros, batch_size = batch_size,\n                               ctx=context)\n    for i in range(0, data_source.shape[0] - 1, num_steps):\n        data, target = get_batch(data_source, i)\n        output, hidden = model(data, hidden)\n        L = loss(output, target)\n        total_L += mx.nd.sum(L).asscalar()\n        ntotal += L.size\n    return total_L / ntotal"
        }, 
        {
            "source": "\u6700\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u8bad\u7ec3\u6a21\u578b\u5e76\u5728\u6bcf\u4e2aepoch\u8bc4\u4ef7\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u7ed3\u679c\u3002\u6211\u4eec\u53ef\u4ee5\u53c2\u8003\u9a8c\u8bc1\u96c6\u4e0a\u7684\u7ed3\u679c\u8c03\u53c2\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "10"
                }
            }, 
            "outputs": [], 
            "source": "def train():\n    for epoch in range(epochs):\n        total_L = 0.0\n        start_time = time.time()\n        hidden = model.begin_state(func = mx.nd.zeros, batch_size = batch_size,\n                                   ctx = context)\n        for ibatch, i in enumerate(range(0, train_data.shape[0] - 1, num_steps)):\n            data, target = get_batch(train_data, i)\n            # \u4ece\u8ba1\u7b97\u56fe\u5206\u79bb\u9690\u542b\u72b6\u6001\u3002\n            hidden = detach(hidden)\n            with autograd.record():\n                output, hidden = model(data, hidden)\n                L = loss(output, target)\n                L.backward()\n\n            grads = [i.grad(context) for i in model.collect_params().values()]\n            # \u68af\u5ea6\u88c1\u526a\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u91cc\u7684\u68af\u5ea6\u662f\u6574\u4e2a\u6279\u91cf\u7684\u68af\u5ea6\u3002\n            # \u56e0\u6b64\u6211\u4eec\u5c06clipping_norm\u4e58\u4ee5num_steps\u548cbatch_size\u3002\n            gluon.utils.clip_global_norm(grads,\n                                         clipping_norm * num_steps * batch_size)\n\n            trainer.step(batch_size)\n            total_L += mx.nd.sum(L).asscalar()\n\n            if ibatch % eval_period == 0 and ibatch > 0:\n                cur_L = total_L / num_steps / batch_size / eval_period\n                print('[Epoch %d Batch %d] loss %.2f, perplexity %.2f' % (\n                    epoch + 1, ibatch, cur_L, math.exp(cur_L)))\n                total_L = 0.0\n\n        val_L = model_eval(val_data)\n\n        print('[Epoch %d] time cost %.2fs, validation loss %.2f, validation ' \n              'perplexity %.2f' % (epoch + 1, time.time() - start_time, val_L,\n                                   math.exp(val_L)))"
        }, 
        {
            "source": "\u8bad\u7ec3\u5b8c\u6a21\u578b\u4ee5\u540e\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4ef7\u6a21\u578b\u4e86\u3002", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "11"
                }
            }, 
            "outputs": [], 
            "source": "train()\ntest_L = model_eval(test_data)\nprint('Test loss %.2f, test perplexity %.2f' % (test_L, math.exp(test_L)))"
        }, 
        {
            "source": "## \u7ed3\u8bba\n\n* \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528Gluon\u8f7b\u677e\u8bad\u7ec3\u5404\u79cd\u4e0d\u540c\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u8bbe\u7f6e\u7f51\u7edc\u53c2\u6570\uff0c\u4f8b\u5982\u7f51\u7edc\u7684\u5c42\u6570\u3002\n* \u8bad\u7ec3\u8fed\u4ee3\u4e2d\u9700\u8981\u5c06\u9690\u542b\u72b6\u6001\u4ece\u8ba1\u7b97\u56fe\u4e2d\u5206\u79bb\uff0c\u4f7f\u6a21\u578b\u53c2\u6570\u68af\u5ea6\u8ba1\u7b97\u53ea\u4f9d\u8d56\u5f53\u524d\u7684\u65f6\u5e8f\u6570\u636e\u6279\u91cf\u91c7\u6837\u3002\n\n\n## \u7ec3\u4e60\n\n* \u8c03\u8c03\u53c2\u6570\uff08\u4f8b\u5982epochs\u3001\u9690\u542b\u5c42\u7684\u5c42\u6570\u3001\u5e8f\u5217\u957f\u5ea6\u3001\u9690\u542b\u72b6\u6001\u957f\u5ea6\u548c\u5b66\u4e60\u7387\uff09\uff0c\u770b\u770b\u5bf9\u8fd0\u884c\u65f6\u95f4\u3001\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0aperplexity\u9020\u6210\u7684\u5f71\u54cd\u3002\n\n**\u5410\u69fd\u548c\u8ba8\u8bba\u6b22\u8fce\u70b9**[\u8fd9\u91cc](https://discuss.gluon.ai/t/topic/4089)", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 1.6 (Unsupported)", 
            "name": "python2", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}